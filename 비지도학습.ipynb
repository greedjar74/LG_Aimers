{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef72589",
   "metadata": {},
   "source": [
    "# 실습1\n",
    "- KMeans(init='random', n_clusters=3, random_state=100)\n",
    "- fit(irisDF.drop('target', axis=1))\n",
    "- kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293cca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "# 데이터를 불러오고, 데이터 프레임 형태로 만든 후 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    iris = load_iris()\n",
    "    \n",
    "    irisDF = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "    \n",
    "    irisDF['target'] = iris.target\n",
    "    \n",
    "    return irisDF\n",
    "    \n",
    "\"\"\"\n",
    "1. K-means 클러스터링을 \n",
    "   수행하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. K-Means 객체를 불러옵니다.\n",
    "           \n",
    "           군집의 개수는 3, \n",
    "           중심점 초기화는 랜덤,\n",
    "           random_state = 100으로 설정합니다.\n",
    "           \n",
    "   Step02. K-means 클러스터링을 수행합니다.\n",
    "           \n",
    "           클러스터링은 정답이 없는 데이터를\n",
    "           사용하기 때문에 'target' 컬럼을 제거한\n",
    "           데이터를 학습시켜줍니다.\n",
    "           \n",
    "   Step03. 군집화 결과 즉, 각 데이터가 속한 군집\n",
    "           중심점들의 label을 \n",
    "           iris 데이터 프레임에 'cluster' 컬럼으로 추가합니다.\n",
    "\"\"\"\n",
    "def k_means_clus(irisDF):\n",
    "    \n",
    "    kmeans = None\n",
    "    \n",
    "    kmeans.None\n",
    "    \n",
    "    irisDF['cluster'] = None\n",
    "    \n",
    "    # 군집화 결과를 보기 위해 groupby 함수를 사용해보겠습니다.\n",
    "    iris_result = irisDF.groupby(['target','cluster'])['sepal length (cm)'].count()\n",
    "    print(iris_result)\n",
    "    \n",
    "    return iris_result, irisDF\n",
    "\n",
    "# 군집화 결과 시각화하기\n",
    "def Visualize(irisDF):\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca_transformed = pca.fit_transform(irisDF)\n",
    "\n",
    "    irisDF['pca_x'] = pca_transformed[:,0]\n",
    "    irisDF['pca_y'] = pca_transformed[:,1]\n",
    "\n",
    "    # 군집된 값이 0, 1, 2 인 경우, 인덱스 추출\n",
    "    idx_0 = irisDF[irisDF['cluster'] == 0].index\n",
    "    idx_1 = irisDF[irisDF['cluster'] == 1].index\n",
    "    idx_2 = irisDF[irisDF['cluster'] == 2].index\n",
    "    \n",
    "    # 각 군집 인덱스의 pca_x, pca_y 값 추출 및 시각화\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.scatter(x=irisDF.loc[idx_0, 'pca_x'], y= irisDF.loc[idx_0, 'pca_y'], marker = 'o')\n",
    "    ax.scatter(x=irisDF.loc[idx_1, 'pca_x'], y= irisDF.loc[idx_1, 'pca_y'], marker = 's')\n",
    "    ax.scatter(x=irisDF.loc[idx_2, 'pca_x'], y= irisDF.loc[idx_2, 'pca_y'], marker = '^')\n",
    "    ax.set_title('K-menas')\n",
    "    ax.set_xlabel('PCA1')\n",
    "    ax.set_ylabel('PCA2')\n",
    "    \n",
    "    fig.savefig(\"plot.png\")\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    irisDF = load_data()\n",
    "    \n",
    "    iris_result, irisDF = k_means_clus(irisDF)\n",
    "    \n",
    "    Visualize(irisDF)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87a352",
   "metadata": {},
   "source": [
    "# 실습2\n",
    "- GaussianMixture(n_components=3, random_state=100)\n",
    "- fit(irisDF.drop(['target'], axis=1))\n",
    "- gmm.predict(irisDF.drop('target', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4938247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "# 데이터를 불러오고, 데이터 프레임 형태로 만든 후 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    iris = load_iris()\n",
    "    \n",
    "    irisDF = pd.DataFrame(data = iris.data, columns = iris.feature_names)\n",
    "    \n",
    "    irisDF['target'] = iris.target\n",
    "    \n",
    "    return irisDF\n",
    "    \n",
    "\"\"\"\n",
    "1. GMM 클러스터링을 \n",
    "   수행하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. GMM 객체를 불러옵니다.\n",
    "           \n",
    "           군집의 개수는 3,\n",
    "           일관된 결과 확인을 위해 \n",
    "           random_state를 100으로 설정합니다.\n",
    "           \n",
    "   Step02. GMM 클러스터링을 수행합니다.\n",
    "           \n",
    "           클러스터링은 정답이 없는 데이터를\n",
    "           사용하기 때문에 'target' 컬럼을 제거한\n",
    "           데이터를 학습시켜줍니다.\n",
    "           \n",
    "   Step03. 군집화 결과를 \n",
    "           iris 데이터 프레임에 'cluster' 컬럼으로 추가합니다.\n",
    "           \n",
    "\"\"\"\n",
    "def gmm_clus(irisDF):\n",
    "    \n",
    "    gmm = None\n",
    "    \n",
    "    gmm.None\n",
    "    \n",
    "    irisDF['cluster'] = None\n",
    "    \n",
    "    # 군집화 결과를 보기 위해 groupby 함수를 사용해보겠습니다.\n",
    "    iris_result = irisDF.groupby(['target','cluster'])['sepal length (cm)'].count()\n",
    "    print(iris_result)\n",
    "    \n",
    "    return iris_result, irisDF\n",
    "\n",
    "# 군집화 결과 시각화하기\n",
    "def Visualize(irisDF):\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca_transformed = pca.fit_transform(irisDF)\n",
    "\n",
    "    irisDF['pca_x'] = pca_transformed[:,0]\n",
    "    irisDF['pca_y'] = pca_transformed[:,1]\n",
    "\n",
    "    # 군집된 값이 0, 1, 2 인 경우, 인덱스 추출\n",
    "    idx_0 = irisDF[irisDF['cluster'] == 0].index\n",
    "    idx_1 = irisDF[irisDF['cluster'] == 1].index\n",
    "    idx_2 = irisDF[irisDF['cluster'] == 2].index\n",
    "    \n",
    "    # 각 군집 인덱스의 pca_x, pca_y 값 추출 및 시각화\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.scatter(x=irisDF.loc[idx_0, 'pca_x'], y= irisDF.loc[idx_0, 'pca_y'], marker = 'o')\n",
    "    ax.scatter(x=irisDF.loc[idx_1, 'pca_x'], y= irisDF.loc[idx_1, 'pca_y'], marker = 's')\n",
    "    ax.scatter(x=irisDF.loc[idx_2, 'pca_x'], y= irisDF.loc[idx_2, 'pca_y'], marker = '^')\n",
    "    ax.set_title('GMM')\n",
    "    ax.set_xlabel('PCA1')\n",
    "    ax.set_ylabel('PCA2')\n",
    "    \n",
    "    fig.savefig(\"plot.png\")\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    irisDF = load_data()\n",
    "    \n",
    "    iris_result, irisDF = gmm_clus(irisDF)\n",
    "    \n",
    "    Visualize(irisDF)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48048a6",
   "metadata": {},
   "source": [
    "# 실습3\n",
    "- make_blobs(n_samples=300, n_features=2, centers=3, cluster_std=0.8, random_state=0)\n",
    "- KMeans(init='random', n_clusters=3, random_state=0)\n",
    "- k_means.fit(X_aniso).labels_\n",
    "- GaussianMixture(n_components=3, random_state=0)\n",
    "- gmm.fit_predict(X_aniso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e1c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "\"\"\"\n",
    "1. 지시 사항과 동일한 타원형 분포의 데이터를\n",
    "   생성합니다.\n",
    "   \n",
    "   Step01. 타원형 분포의 데이터를 생성합니다.\n",
    "           \n",
    "           데이터의 개수는 300개,\n",
    "           데이터 변수의 개수는 2개,\n",
    "           군집의 개수는 3개,\n",
    "           데이터의 표준편차는 0.8,\n",
    "           random_state 는 0으로 설정합니다.\n",
    "\"\"\"\n",
    "# make_blobs()으로 데이터를 생성해보세요.\n",
    "X, y = None\n",
    "\n",
    "# 데이터의 분포를 변형시키기 위해 transformation을 진행합니다.\n",
    "transformation = [[0.60834549, -0.63667341],[-0.40887718,0.85253229]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "\n",
    "# 데이터 프레임 만들기 \n",
    "clusterDF = pd.DataFrame(data = X_aniso, columns= ['ftr1','ftr2'])\n",
    "clusterDF['target'] = y\n",
    "target_list = np.unique(y)\n",
    "\n",
    "# 생성된 데이터 시각화\n",
    "def data_visualize():\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('data')\n",
    "    \n",
    "    for target in target_list:\n",
    "        target_cluster = clusterDF[clusterDF['target'] == target]\n",
    "        ax.scatter(x = target_cluster['ftr1'], y = target_cluster['ftr2'])\n",
    "    \n",
    "    fig.savefig(\"plot.png\")\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "2. K-Means 클러스터링을 수행하여\n",
    "   클러스터링 결과를 데이터 프레임 내에 \n",
    "   저장하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 데이터 X_aniso에 대한 K-Means \n",
    "           클러스터링을 수행합니다.\n",
    "           \n",
    "           초기화 방식은 랜덤,\n",
    "           군집의 개수는 3개, \n",
    "           random_state는 0으로 설정합니다.\n",
    "           \n",
    "    Step02. kmeans_label 변수에\n",
    "            클러스터링 결과를 저장합니다.\n",
    "\"\"\"\n",
    "def K_means():\n",
    "    \n",
    "    k_means = None\n",
    "    \n",
    "    kmeans_label = None\n",
    "    \n",
    "    clusterDF['kmeans_label']=kmeans_label\n",
    "    \n",
    "    # Kmeans 군집의 중심값을 뽑아 저장합니다.\n",
    "    center = k_means.cluster_centers_\n",
    "    \n",
    "    # KMeans 군집 결과를 시각화합니다.\n",
    "    unique_labels = np.unique(kmeans_label)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('K-Means')\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_cluster = clusterDF[clusterDF['kmeans_label'] == label]\n",
    "        center_x_y = center[label]\n",
    "        ax.scatter(x = label_cluster['ftr1'], y = label_cluster['ftr2'])\n",
    "        ax.scatter(x = center_x_y[0], y = center_x_y[1], s = 70,color = 'k', marker = '$%d$' % label)\n",
    "    \n",
    "    fig.savefig(\"plot.png\")\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "\n",
    "    print(\"K-means Clustering\")\n",
    "    print(clusterDF.groupby('target')['kmeans_label'].value_counts())\n",
    "    \n",
    "    return kmeans_label\n",
    "    \n",
    "\"\"\"\n",
    "3. GMM 클러스터링을 수행하여\n",
    "   클러스터링 결과를 데이터 프레임 내에 \n",
    "   저장하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 데이터 X_aniso에 대한 \n",
    "           GMM 클러스터링을 수행합니다.\n",
    "           \n",
    "           군집의 개수는 3개, \n",
    "           random_state는 0으로 설정합니다.\n",
    "           \n",
    "   Step02. gmm_label 변수에\n",
    "           클러스터링 결과를 저장합니다.\n",
    "            \n",
    "\"\"\"\n",
    "def GMM():\n",
    "    \n",
    "    gmm = None\n",
    "    \n",
    "    gmm_label = None\n",
    "    \n",
    "    clusterDF['gmm_label']=gmm_label\n",
    "    \n",
    "    unique_labels = np.unique(gmm_label)\n",
    "    \n",
    "    # GMM 군집 결과를 시각화합니다.\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('GMM')\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_cluster = clusterDF[clusterDF['gmm_label'] == label]\n",
    "        plt.scatter(x = label_cluster['ftr1'], y = label_cluster['ftr2'])\n",
    "    \n",
    "    fig.savefig(\"plot.png\")\n",
    "    elice_utils.send_image(\"plot.png\")\n",
    "    \n",
    "    print(\"Gaussian Mixture Model\")\n",
    "    print(clusterDF.groupby('target')['gmm_label'].value_counts())\n",
    "    \n",
    "    return gmm_label\n",
    "\n",
    "def main():\n",
    "    data_visualize()\n",
    "    K_means()\n",
    "    GMM()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709a8fa",
   "metadata": {},
   "source": [
    "# 실습4\n",
    "- load_wine(return_X_y=True)\n",
    "- PCA(n_components=1)\n",
    "- fit(X)\n",
    "- pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e613e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "1. 사이킷런에 저장된 데이터를 불러오고, \n",
    "   2개의 변수만을 가질 수 있도록 \n",
    "   고정하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. load_wine()을 활용해 사이킷런에 저장된 와인 데이터를 불러옵니다.\n",
    "           데이터는 (X, y) 형태로 불러와야 합니다. (return_X_y를 True로 지정해야 합니다)\n",
    "           \n",
    "   Step02. column_start로 지정된 특정 column으로부터\n",
    "           연속되는 2개의 변수를 X에 저장합니다.\n",
    "          \n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    X, y = None\n",
    "    \n",
    "    column_start = 6\n",
    "    X = X[:, column_start : column_start+2]\n",
    "    print(X.shape)\n",
    "    return X\n",
    "    \n",
    "\"\"\"\n",
    "2. 주성분 분석(PCA)을 수행하여 \n",
    "   2차원 데이터를 1차원으로 축소하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. PCA의 n_components를 1로 지정하여 \n",
    "           pca 를 정의합니다.\n",
    "           \n",
    "   Step02. 주성분 분석을 수행합니다.\n",
    "   \n",
    "   Step03. X_pca 값을 추출합니다.\n",
    "\"\"\"\n",
    "def pca_data(X):\n",
    "    \n",
    "    pca = None\n",
    "    \n",
    "    pca.None\n",
    "    \n",
    "    X_pca = None\n",
    "    \n",
    "    return pca, X_pca\n",
    "\n",
    "# 축소된 주성분 축과 데이터 산점도를 그려주는 함수입니다.\n",
    "def visualize(pca, X, X_pca):\n",
    "    X_new = pca.inverse_transform(X_pca)\n",
    "    \n",
    "    plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "    plt.scatter(X_new[:, 0], X_new[:, 1], alpha=0.8)\n",
    "    plt.axis('equal');\n",
    "    \n",
    "    plt.savefig('PCA.png')\n",
    "    elice_utils.send_image('PCA.png')\n",
    "\n",
    "def main():\n",
    "    \n",
    "    X = load_data()\n",
    "    \n",
    "    pca, X_pca = pca_data(X)\n",
    "    \n",
    "    print(\"- original shape:   \", X.shape)\n",
    "    print(\"- transformed shape:\", X_pca.shape)\n",
    "    \n",
    "    visualize(pca, X, X_pca)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479dbf9d",
   "metadata": {},
   "source": [
    "# 실습5\n",
    "- load_wine(return_X_y=True)\n",
    "- TSNE(n_components=1)\n",
    "- tsne.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2081d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "\"\"\"\n",
    "1. 사이킷런에 저장된 데이터를 불러오고, \n",
    "   2개의 변수만을 가질 수 있도록 \n",
    "   고정하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. load_wine()을 활용해 사이킷런에 저장된 와인 데이터를 불러옵니다.\n",
    "           데이터는 (X, y) 형태로 불러와야 합니다. (return_X_y를 True로 지정해야 합니다)\n",
    "           \n",
    "   Step02. column_start로 지정된 특정 column으로부터\n",
    "           연속되는 2개의 변수를 X에 저장합니다.\n",
    "          \n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    X, y = None\n",
    "    \n",
    "    column_start = 6\n",
    "    X = X[:, column_start : column_start+2]\n",
    "    print(X.shape)\n",
    "    return X\n",
    "    \n",
    "\"\"\"\n",
    "2. t-SNE를 활용하여 \n",
    "   2차원 데이터를 1차원으로 축소하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. t-SNE의 n_components를 1로 지정하여 \n",
    "           tsne를 정의합니다.\n",
    "           \n",
    "   Step02. tsne를 활용하여 차원 축소를 진행한 후,\n",
    "           차원이 축소된 데이터 X_tsne를 추출합니다.\n",
    "\"\"\"\n",
    "def tsne_data(X):\n",
    "    \n",
    "    tsne = None\n",
    "    \n",
    "    X_tsne = None\n",
    "    \n",
    "    return tsne, X_tsne\n",
    "\n",
    "def main():\n",
    "    \n",
    "    X = load_data()\n",
    "    \n",
    "    tsne, X_tsne = tsne_data(X)\n",
    "    \n",
    "    print(\"- original shape:   \", X.shape)\n",
    "    print(\"- transformed shape:\", X_tsne.shape)\n",
    "    \n",
    "    print(\"\\n원본 데이터 X :\\n\", X[:5])\n",
    "    print(\"\\n차원 축소 이후 데이터 X_tsne\\n\",X_tsne[:5])\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d6db4",
   "metadata": {},
   "source": [
    "# 실습6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import numpy as np\n",
    "import pylab as Plot\n",
    "import matplotlib.cm as cm\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import tsne\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def sample_data(n_samples):\n",
    "\tX = np.loadtxt(\"data/mnist2500_X.txt\");\n",
    "\tlabels = np.loadtxt(\"data/mnist2500_labels.txt\");\n",
    "    \n",
    "    # 데이터를 랜덤 샘플링 합니다.\n",
    "\tnp.random.seed(0)\n",
    "\tsample_idx = np.random.choice(list(range(2500)), n_samples, replace=False)\n",
    "\tsampled_labels = labels[sample_idx]\n",
    "\tsampled_X = X[sample_idx]\n",
    "\treturn sampled_X, sampled_labels\n",
    "\n",
    "def pca(X, no_dims):\n",
    "\tscaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\tX_scaled = scaler.fit_transform(np.array(X).astype('float64'))\n",
    "\tmu = np.mean(X_scaled, axis=0)\n",
    "\tX_scaled -= mu\n",
    "\n",
    "\tmodel = PCA(n_components=no_dims)\n",
    "\tY = model.fit_transform(X_scaled)\n",
    "\treturn Y\n",
    "\n",
    "def main():\n",
    "\t# 데이터를 불러옵니다.\n",
    "\tprint(\"Loading data...\")\n",
    "\tX, labels = sample_data(1000)\n",
    "\n",
    "\t# PCA를 실행합니다.\n",
    "\tprint(\"Run Y = pca(X, no_dims) to perform PCA on your dataset.\")\n",
    "\tY = pca(X, 2)\n",
    "    \n",
    "\t# PCA의 결과를 시각화합니다.\n",
    "\tlegend_ = []; colors = cm.rainbow(np.linspace(0, 1, 10))\n",
    "\tfor i in sorted(list(set(labels))):\n",
    "\t\tidxs = (labels==i).nonzero()\n",
    "\t\tl = Plot.scatter(np.squeeze(Y[idxs,0]), Y[idxs,1], 20, color=colors[int(i)])\n",
    "\t\tlegend_.append(l)\n",
    "\tPlot.legend(legend_, list(range(10)), loc='center left', ncol=1, fontsize=8, bbox_to_anchor=(1, 0.5))\n",
    "\tPlot.savefig(\"result.png\");\n",
    "\telice_utils.send_image(\"result.png\")\n",
    "    \n",
    "     # t-SNE.py 파일을 불러와 t-SNE를 실행합니다.\n",
    "\tprint(\"Run Z = tsne.tsne(X, no_dims, initial_dims, perplexity) to perform t-SNE on your dataset.\")\n",
    "\tZ = tsne.tsne(X, 2, 50, 30.0);\n",
    "    \n",
    "    # t-SNE의 결과를 시각화합니다.\n",
    "\tlegend2_ = []; colors2 = cm.rainbow(np.linspace(0, 1, 10))\n",
    "\tfor i in sorted(list(set(labels))):\n",
    "\t\tidxs = (labels==i).nonzero()\n",
    "\t\tl2 = Plot.scatter(np.squeeze(Z[idxs,0]), Z[idxs,1], 20, color=colors2[int(i)])\n",
    "\t\tlegend2_.append(l2)\n",
    "\tPlot.legend(legend2_, list(range(10)), loc='center left', ncol=1, fontsize=8, bbox_to_anchor=(1, 0.5))\n",
    "\tPlot.savefig(\"result2.png\");\n",
    "\telice_utils.send_image(\"result2.png\")\n",
    "\t\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ee89d",
   "metadata": {},
   "source": [
    "# 실습7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "\"\"\"\n",
    "    1. digits 데이터를 불러오는\n",
    "       load_data() 함수를 구현합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\"\"\"\n",
    "    2. PCA 알고리즘을 활용하여 차원을 축소하고,\n",
    "       다시 이미지로 복원한 결과를 확인하기 위한\n",
    "       train_PCA_and_restore_image() 함수를 구현합니다.\n",
    "       \n",
    "       Step01. dim_reduction_number개의 차원으로 축소하는 \n",
    "               PCA 모델을 생성합니다.\n",
    "       \n",
    "       Step02. 생성한 PCA 모델을 이용하여 차원 축소를 진행합니다.\n",
    "       \n",
    "       Step03. 축소된 데이터를 다시 이미지 데이터로 복원합니다.\n",
    "       \n",
    "       Step04. 축소된 이미지의 log-likelihood를 통해 점수를 확인합니다.\n",
    "\"\"\"\n",
    "def train_PCA_and_restore_image(dim_reduction_number, images): \n",
    "    \n",
    "    \n",
    "    return approxOriginal, score\n",
    "    \n",
    "\"\"\"\n",
    "digit 이미지를 시각화합니다.\n",
    "\"\"\"\n",
    "def visualize(X, x_label, title):\n",
    "    \n",
    "    plt.figure(figsize=(5,4));\n",
    "    n_data = 100\n",
    "    \n",
    "    plt.imshow(X[n_data].reshape(8, 8),\n",
    "                  cmap = plt.cm.gray, interpolation='nearest')\n",
    "    plt.xlabel(x_label, fontsize = 12)\n",
    "    plt.title(title, fontsize = 14)\n",
    "    \n",
    "    plt.savefig('PCA.png')\n",
    "    elice_utils.send_image('PCA.png')\n",
    "    \n",
    "\"\"\"\n",
    "    3. 구현한 함수를 활용하여 차원 축소를 진행하고\n",
    "       시각화해주는 main() 함수를 완성합니다.\n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    X,y = load_data()\n",
    "    \n",
    "    # 차원 축소와 이미지 복원 진행하기\n",
    "    reduced_image_32, score_32 = None\n",
    "    reduced_image_16, score_16 = None\n",
    "    reduced_image_8, score_8 = None\n",
    "    reduced_image_4, score_4 = None\n",
    "    \n",
    "    # 시각화 함수 호출하기\n",
    "    visualize(X, '64', 'Original_data')\n",
    "    visualize(reduced_image_32, '32', '32 dim')\n",
    "    visualize(reduced_image_16, '16', '16 dim')\n",
    "    visualize(reduced_image_8, '8', '8 dim')\n",
    "    visualize(reduced_image_4, '4', '4 dim')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d34561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1f1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395c288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917e9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d254dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818be975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf015f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b2161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa561b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b766c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d795cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0b593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26b480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b173bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d8bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47451dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb8ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a4292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75aecfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb377938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64e993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704fc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a8101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b7e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a0c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721995b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772dc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8f70d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa3d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388b4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c330157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e31af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab5d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34be48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650d8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16575692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d63cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738175f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa59d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ae534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c54e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ba87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092f876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88143914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71d02d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
