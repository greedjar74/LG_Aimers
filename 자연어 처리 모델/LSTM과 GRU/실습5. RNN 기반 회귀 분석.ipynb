{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac0cee5",
   "metadata": {},
   "source": [
    "# RNN 기반 모델을 통한 회귀 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19442e6",
   "metadata": {},
   "source": [
    "지시사항\n",
    "지난 실습까지는 사용한 시계열 데이터셋 모두 각 시점의 feature 개수가 하나뿐이었습니다. 즉, 한 시점에 모델에 들어가는 값은 오직 하나뿐이었다는 의미입니다.\n",
    "\n",
    "이번 실습에서는 각 시점에 시작가, 일 최고가, 일 최저가, 종가의 4개 값을 사용하여 모델을 학습하도록 할 것입니다. 즉, 각 시점의feature 개수를 4개로 구성할 것입니다.\n",
    "\n",
    "그리고 모델에 한번에 넣어줄 시점의 개수, window size는 30개로 설정할 것입니다. 주말엔 주식 시장이 열리지 않으므로 대략 한달 이상의 기간을 보고 입력 데이터 내 마지막 날짜 다음날의 종가를 예측하도록 모델을 학습할 것입니다.\n",
    "\n",
    "SimpleRNN 기반 모델을 만드는 함수 build_rnn_model을 완성하세요. 각 Layer 구성은 아래와 같습니다.\n",
    "layers.SimpleRNN\n",
    "hidden state의 크기: 256\n",
    "input_shape=(window_size, num_features)\n",
    "layers.Dense\n",
    "노드 개수: 64개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 16개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 1개\n",
    "\n",
    "LSTM 기반 모델을 만드는 함수 build_lstm_model을 완성하세요. 각 Layer 구성은 아래와 같습니다.\n",
    "layers.LSTM\n",
    "hidden state의 크기: 256\n",
    "input_shape=(window_size, num_features)\n",
    "layers.Dense\n",
    "노드 개수: 64개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 16개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 1개\n",
    "\n",
    "GRU 기반 모델을 만드는 함수 build_gru_model을 완성하세요. 각 Layer 구성은 아래와 같습니다.\n",
    "layers.GRU\n",
    "hidden state의 크기: 256\n",
    "input_shape=(window_size, num_features)\n",
    "layers.Dense\n",
    "노드 개수: 64개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 16개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 1개\n",
    "\n",
    "run_model 함수 내에서 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "Optimizer: Adam\n",
    "Learning Rate: 0.001\n",
    "Loss 함수: Mean Squared Error(MSE)\n",
    "\n",
    "run_model 함수 내에서 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "batch_size=128\n",
    "epochs=epochs\n",
    "shuffle=True\n",
    "verbose=2\n",
    "실행이 완료되면 아래와 같이 세가지 모델이 예측한 결과 그래프가 나올 것입니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def load_data(window_size):\n",
    "    raw_data_df = pd.read_csv(\"./AAPL.csv\", index_col=\"Date\")\n",
    "    \n",
    "    # 데이터 전체를 표준화합니다.\n",
    "    scaler = StandardScaler()\n",
    "    raw_data = scaler.fit_transform(raw_data_df)\n",
    "    plot_data = {\"mean\": scaler.mean_[3], \"var\": scaler.var_[3], \"date\": raw_data_df.index}\n",
    "\n",
    "    # 입력 데이터(X)는 시작가, 일 최고가, 일 최저가, 종가 데이터를 사용하고\n",
    "    # 라벨 데이터(y)는 4번째 컬럼에 해당하는 종가 데이터만 사용합니다.\n",
    "    raw_X = raw_data[:, :4]\n",
    "    raw_y = raw_data[:, 3]\n",
    "\n",
    "    # window_size 개의 데이터를 불러와 입력 데이터(X)로 설정하고\n",
    "    # window_size보다 한 시점 뒤의 데이터를 예측할 대상(y)으로 설정하여\n",
    "    # 데이터셋을 구성합니다.\n",
    "    X, y = [], []\n",
    "    for i in range(len(raw_X) - window_size):\n",
    "        cur_prices = raw_X[i:i + window_size, :]\n",
    "        target = raw_y[i + window_size]\n",
    "\n",
    "        X.append(list(cur_prices))\n",
    "        y.append(target)\n",
    "\n",
    "    # X와 y를 numpy array로 변환합니다.\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 학습 데이터는 전체 데이터의 80%, 테스트 데이터는 20%로 설정합니다.\n",
    "    total_len = len(X)\n",
    "    train_len = int(total_len * 0.8)\n",
    "\n",
    "    X_train, y_train = X[:train_len], y[:train_len]\n",
    "    X_test, y_test = X[train_len:], y[train_len:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, plot_data\n",
    "\n",
    "def build_rnn_model(window_size, num_features):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 1번] SimpleRNN 기반 모델을 구성하세요.\n",
    "    model.add(None)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(window_size, num_features):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 2번] LSTM 기반 모델을 구성하세요.\n",
    "    model.add(None)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_gru_model(window_size, num_features):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 3번] GRU 기반 모델을 구성하세요.\n",
    "    model.add(None)\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_model(model, X_train, X_test, y_train, y_test, epochs=10, name=None):\n",
    "    # TODO: [지시사항 4번] 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "    optimizer = None\n",
    "    None\n",
    "\n",
    "    # TODO: [지시사항 5번] 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "    hist = None\n",
    "    \n",
    "    # 테스트 데이터셋으로 모델을 테스트합니다.\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"[{}] 테스트 loss: {:.5f}\".format(name, test_loss))\n",
    "    print()\n",
    "\n",
    "    return optimizer, hist\n",
    "\n",
    "def plot_result(model, X_true, y_true, plot_data, name):\n",
    "    y_pred = model.predict(X_true)\n",
    "\n",
    "    # 표준화된 결과를 다시 원래 값으로 변환합니다.\n",
    "    y_true_orig = (y_true * np.sqrt(plot_data[\"var\"])) + plot_data[\"mean\"]\n",
    "    y_pred_orig = (y_pred * np.sqrt(plot_data[\"var\"])) + plot_data[\"mean\"]\n",
    "\n",
    "    # 테스트 데이터에서 사용한 날짜들만 가져옵니다.\n",
    "    test_date = plot_data[\"date\"][-len(y_true):]\n",
    "\n",
    "    # 모델의 예측값을 실제값과 함께 그래프로 그립니다.\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(y_true_orig, color=\"b\", label=\"True\")\n",
    "    ax.plot(y_pred_orig, color=\"r\", label=\"Prediction\")\n",
    "    ax.set_xticks(list(range(len(test_date))))\n",
    "    ax.set_xticklabels(test_date, rotation=45)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "    ax.set_title(\"{} Result\".format(name))\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"apple_stock_{}\".format(name.lower()))\n",
    "    \n",
    "    elice_utils.send_image(\"apple_stock_{}.png\".format(name.lower()))\n",
    "\n",
    "def main():\n",
    "    tf.random.set_seed(2022)\n",
    "\n",
    "    window_size = 30\n",
    "    X_train, X_test, y_train, y_test, plot_data = load_data(window_size)\n",
    "    num_features = X_train[0].shape[1]\n",
    "\n",
    "    rnn_model = build_rnn_model(window_size, num_features)\n",
    "    lstm_model = build_lstm_model(window_size, num_features)\n",
    "    gru_model = build_gru_model(window_size, num_features)\n",
    "\n",
    "    run_model(rnn_model, X_train, X_test, y_train, y_test, name=\"RNN\")\n",
    "    run_model(lstm_model, X_train, X_test, y_train, y_test, name=\"LSTM\")\n",
    "    run_model(gru_model, X_train, X_test, y_train, y_test, name=\"GRU\")\n",
    "\n",
    "    plot_result(rnn_model, X_test, y_test, plot_data, name=\"RNN\")\n",
    "    plot_result(lstm_model, X_test, y_test, plot_data, name=\"LSTM\")\n",
    "    plot_result(gru_model, X_test, y_test, plot_data, name=\"GRU\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def load_data(window_size):\n",
    "    raw_data_df = pd.read_csv(\"./AAPL.csv\", index_col=\"Date\")\n",
    "    \n",
    "    # 데이터 전체를 표준화합니다.\n",
    "    scaler = StandardScaler()\n",
    "    raw_data = scaler.fit_transform(raw_data_df)\n",
    "    plot_data = {\"mean\": scaler.mean_[3], \"var\": scaler.var_[3], \"date\": raw_data_df.index}\n",
    "\n",
    "    # 입력 데이터(X)는 시작가, 일 최고가, 일 최저가, 종가 데이터를 사용하고\n",
    "    # 라벨 데이터(y)는 4번째 컬럼에 해당하는 종가 데이터만 사용합니다.\n",
    "    raw_X = raw_data[:, :4]\n",
    "    raw_y = raw_data[:, 3]\n",
    "\n",
    "    # window_size 개의 데이터를 불러와 입력 데이터(X)로 설정하고\n",
    "    # window_size보다 한 시점 뒤의 데이터를 예측할 대상(y)으로 설정하여\n",
    "    # 데이터셋을 구성합니다.\n",
    "    X, y = [], []\n",
    "    for i in range(len(raw_X) - window_size):\n",
    "        cur_prices = raw_X[i:i + window_size, :]\n",
    "        target = raw_y[i + window_size]\n",
    "\n",
    "        X.append(list(cur_prices))\n",
    "        y.append(target)\n",
    "\n",
    "    # X와 y를 numpy array로 변환합니다.\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 학습 데이터는 전체 데이터의 80%, 테스트 데이터는 20%로 설정합니다.\n",
    "    total_len = len(X)\n",
    "    train_len = int(total_len * 0.8)\n",
    "\n",
    "    X_train, y_train = X[:train_len], y[:train_len]\n",
    "    X_test, y_test = X[train_len:], y[train_len:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, plot_data\n",
    "\n",
    "def build_rnn_model(window_size, num_features):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 1번] SimpleRNN 기반 모델을 구성하세요.\n",
    "    model.add(tf.keras.layers.SimpleRNN(256, input_shape=(window_size, num_features)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(window_size, num_features):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 2번] LSTM 기반 모델을 구성하세요.\n",
    "    model.add(tf.keras.layers.LSTM(256, input_shape=(window_size, num_features)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_gru_model(window_size, num_features):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 3번] GRU 기반 모델을 구성하세요.\n",
    "    model.add(tf.keras.layers.GRU(256, input_shape=(window_size, num_features)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_model(model, X_train, X_test, y_train, y_test, epochs=10, name=None):\n",
    "    # TODO: [지시사항 4번] 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "\n",
    "    # TODO: [지시사항 5번] 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "    hist = model.fit(X_train, y_train, batch_size=128, epochs=epochs, shuffle=True, verbose=2)\n",
    "    \n",
    "    # 테스트 데이터셋으로 모델을 테스트합니다.\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"[{}] 테스트 loss: {:.5f}\".format(name, test_loss))\n",
    "    print()\n",
    "\n",
    "    return optimizer, hist\n",
    "\n",
    "def plot_result(model, X_true, y_true, plot_data, name):\n",
    "    y_pred = model.predict(X_true)\n",
    "\n",
    "    # 표준화된 결과를 다시 원래 값으로 변환합니다.\n",
    "    y_true_orig = (y_true * np.sqrt(plot_data[\"var\"])) + plot_data[\"mean\"]\n",
    "    y_pred_orig = (y_pred * np.sqrt(plot_data[\"var\"])) + plot_data[\"mean\"]\n",
    "\n",
    "    # 테스트 데이터에서 사용한 날짜들만 가져옵니다.\n",
    "    test_date = plot_data[\"date\"][-len(y_true):]\n",
    "\n",
    "    # 모델의 예측값을 실제값과 함께 그래프로 그립니다.\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(y_true_orig, color=\"b\", label=\"True\")\n",
    "    ax.plot(y_pred_orig, color=\"r\", label=\"Prediction\")\n",
    "    ax.set_xticks(list(range(len(test_date))))\n",
    "    ax.set_xticklabels(test_date, rotation=45)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "    ax.set_title(\"{} Result\".format(name))\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"apple_stock_{}\".format(name.lower()))\n",
    "    \n",
    "    elice_utils.send_image(\"apple_stock_{}.png\".format(name.lower()))\n",
    "\n",
    "def main():\n",
    "    tf.random.set_seed(2022)\n",
    "\n",
    "    window_size = 30\n",
    "    X_train, X_test, y_train, y_test, plot_data = load_data(window_size)\n",
    "    num_features = X_train[0].shape[1]\n",
    "\n",
    "    rnn_model = build_rnn_model(window_size, num_features)\n",
    "    lstm_model = build_lstm_model(window_size, num_features)\n",
    "    gru_model = build_gru_model(window_size, num_features)\n",
    "\n",
    "    run_model(rnn_model, X_train, X_test, y_train, y_test, name=\"RNN\")\n",
    "    run_model(lstm_model, X_train, X_test, y_train, y_test, name=\"LSTM\")\n",
    "    run_model(gru_model, X_train, X_test, y_train, y_test, name=\"GRU\")\n",
    "\n",
    "    plot_result(rnn_model, X_test, y_test, plot_data, name=\"RNN\")\n",
    "    plot_result(lstm_model, X_test, y_test, plot_data, name=\"LSTM\")\n",
    "    plot_result(gru_model, X_test, y_test, plot_data, name=\"GRU\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
