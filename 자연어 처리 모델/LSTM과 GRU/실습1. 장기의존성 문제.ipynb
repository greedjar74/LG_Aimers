{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558f532a",
   "metadata": {},
   "source": [
    "# 장기 의존성 문제 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c62daa",
   "metadata": {},
   "source": [
    "지시사항\n",
    "시계열 데이터를 사용하여 RNN 기반 모델을 학습할 때는 window size라는 개념을 사용합니다.\n",
    "\n",
    "이는 모델을 한번 학습할 때 사용할 데이터의 개수를 의미하는 것으로, 아래 그림처럼 총 10개의 데이터에서 4개의 데이터를 한번 학습에 사용한다면 window size는 4가 됩니다.\n",
    "\n",
    "\n",
    "\n",
    "실습에서는 기본적으로 window size가 10개인 경우와 300개인 경우의 성능을 비교하고 있습니다. 각각의 경우에 모델 별로 MSE 점수가 어떻게 나오는지 확인해보세요.\n",
    "\n",
    "SimpleRNN 기반 모델을 만드는 함수 build_rnn_model을 완성하세요. 각 Layer 구성은 아래와 같습니다.\n",
    "layers.SimpleRNN\n",
    "hidden state 크기: 128\n",
    "input_shape=(window_size, 1)\n",
    "layers.Dense\n",
    "노드 개수: 32개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 1개\n",
    "\n",
    "LSTM 기반 모델을 만드는 함수 build_lstm_model을 완성하세요. 각 Layer 구성은 아래와 같습니다.\n",
    "layers.LSTM\n",
    "hidden state 크기: 128\n",
    "input_shape=(window_size, 1)\n",
    "layers.Dense\n",
    "노드 개수: 32개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 1개\n",
    "\n",
    "GRU 기반 모델을 만드는 함수 build_rnn_model을 완성하세요. 각 Layer 구성은 아래와 같습니다.\n",
    "layers.GRU\n",
    "hidden state 크기: 128\n",
    "input_shape=(window_size, 1)\n",
    "layers.Dense\n",
    "노드 개수: 32개\n",
    "활성화 함수: ReLU\n",
    "layers.Dense\n",
    "노드 개수: 1개\n",
    "\n",
    "run_model 함수 내에서 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "Optimizer: Adam\n",
    "Learning Rate: 0.001\n",
    "Loss 함수: Mean Squared Error(MSE)\n",
    "\n",
    "run_model 함수 내에서 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "batch_size=64\n",
    "epochs=epochs\n",
    "shuffle=True\n",
    "verbose=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(window_size):\n",
    "    raw_data = pd.read_csv(\"./daily-min-temperatures.csv\")\n",
    "    raw_temps = raw_data[\"Temp\"]\n",
    "\n",
    "    mean_temp = raw_temps.mean()\n",
    "    stdv_temp = raw_temps.std(ddof=0)\n",
    "    raw_temps = (raw_temps - mean_temp) / stdv_temp\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(raw_temps) - window_size):\n",
    "        cur_temps = raw_temps[i:i + window_size]\n",
    "        target = raw_temps[i + window_size]\n",
    "\n",
    "        X.append(list(cur_temps))\n",
    "        y.append(target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X[:, :, np.newaxis]\n",
    "\n",
    "    total_len = len(X)\n",
    "    train_len = int(total_len * 0.8)\n",
    "\n",
    "    X_train, y_train = X[:train_len], y[:train_len]\n",
    "    X_test, y_test = X[train_len:], y[train_len:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def build_rnn_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 1번] Simple RNN과 Fully-connected Layer로 구성된 모델을 완성하세요.\n",
    "    model.add(None)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 2번] LSTM과 Fully-connected Layer로 구성된 모델을 완성하세요.\n",
    "    model.add(None)\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_gru_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 3번] GRU와 Fully-connected Layer로 구성된 모델을 완성하세요.\n",
    "    model.add(None)\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_model(model, X_train, X_test, y_train, y_test, epochs=10, model_name=None):\n",
    "    # TODO: [지시사항 4번] 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "    optimizer = None\n",
    "    None\n",
    "    \n",
    "    # TODO: [지시사항 5번] 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "    hist = None\n",
    "    \n",
    "    # 테스트 데이터셋으로 모델을 테스트합니다.\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return test_loss, optimizer, hist\n",
    "\n",
    "def main(window_size):\n",
    "    tf.random.set_seed(2022)\n",
    "    X_train, X_test, y_train, y_test = load_data(window_size)\n",
    "\n",
    "    rnn_model = build_rnn_model(window_size)\n",
    "    lstm_model = build_lstm_model(window_size)\n",
    "    gru_model = build_gru_model(window_size)\n",
    "\n",
    "    rnn_test_loss, _, _ = run_model(rnn_model, X_train, X_test, y_train, y_test, model_name=\"RNN\")\n",
    "    lstm_test_loss, _, _ = run_model(lstm_model, X_train, X_test, y_train, y_test, model_name=\"LSTM\")\n",
    "    gru_test_loss, _, _ = run_model(gru_model, X_train, X_test, y_train, y_test, model_name=\"GRU\")\n",
    "    \n",
    "    return rnn_test_loss, lstm_test_loss, gru_test_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 10일치 데이터를 보고 다음날의 기온을 예측합니다.\n",
    "    rnn_10_test_loss, lstm_10_test_loss, gru_10_test_loss = main(10)\n",
    "    \n",
    "    # 300일치 데이터를 보고 다음날의 기온을 예측합니다.\n",
    "    rnn_300_test_loss, lstm_300_test_loss, gru_300_test_loss = main(300)\n",
    "    \n",
    "    print(\"=\" * 20, \"시계열 길이가 10 인 경우\", \"=\" * 20)\n",
    "    print(\"[RNN ] 테스트 MSE = {:.5f}\".format(rnn_10_test_loss))\n",
    "    print(\"[LSTM] 테스트 MSE = {:.5f}\".format(lstm_10_test_loss))\n",
    "    print(\"[GRU ] 테스트 MSE = {:.5f}\".format(gru_10_test_loss))\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 20, \"시계열 길이가 300 인 경우\", \"=\" * 20)\n",
    "    print(\"[RNN ] 테스트 MSE = {:.5f}\".format(rnn_300_test_loss))\n",
    "    print(\"[LSTM] 테스트 MSE = {:.5f}\".format(lstm_300_test_loss))\n",
    "    print(\"[GRU ] 테스트 MSE = {:.5f}\".format(gru_300_test_loss))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(window_size):\n",
    "    raw_data = pd.read_csv(\"./daily-min-temperatures.csv\")\n",
    "    raw_temps = raw_data[\"Temp\"]\n",
    "\n",
    "    mean_temp = raw_temps.mean()\n",
    "    stdv_temp = raw_temps.std(ddof=0)\n",
    "    raw_temps = (raw_temps - mean_temp) / stdv_temp\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(raw_temps) - window_size):\n",
    "        cur_temps = raw_temps[i:i + window_size]\n",
    "        target = raw_temps[i + window_size]\n",
    "\n",
    "        X.append(list(cur_temps))\n",
    "        y.append(target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X[:, :, np.newaxis]\n",
    "\n",
    "    total_len = len(X)\n",
    "    train_len = int(total_len * 0.8)\n",
    "\n",
    "    X_train, y_train = X[:train_len], y[:train_len]\n",
    "    X_test, y_test = X[train_len:], y[train_len:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def build_rnn_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 1번] Simple RNN과 Fully-connected Layer로 구성된 모델을 완성하세요.\n",
    "    model.add(tf.keras.layers.SimpleRNN(128, input_shape=(window_size, 1)))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_lstm_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 2번] LSTM과 Fully-connected Layer로 구성된 모델을 완성하세요.\n",
    "    model.add(tf.keras.layers.LSTM(128, input_shape=(window_size, 1)))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_gru_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 3번] GRU와 Fully-connected Layer로 구성된 모델을 완성하세요.\n",
    "    model.add(tf.keras.layers.GRU(128, input_shape=(window_size, 1)))\n",
    "    model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def run_model(model, X_train, X_test, y_train, y_test, epochs=10, model_name=None):\n",
    "    # TODO: [지시사항 4번] 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "    \n",
    "    # TODO: [지시사항 5번] 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "    hist = model.fit(X_train, y_train, batch_size=64, epochs=epochs, shuffle=True, verbose=2)\n",
    "    \n",
    "    # 테스트 데이터셋으로 모델을 테스트합니다.\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    return test_loss, optimizer, hist\n",
    "\n",
    "def main(window_size):\n",
    "    tf.random.set_seed(2022)\n",
    "    X_train, X_test, y_train, y_test = load_data(window_size)\n",
    "\n",
    "    rnn_model = build_rnn_model(window_size)\n",
    "    lstm_model = build_lstm_model(window_size)\n",
    "    gru_model = build_gru_model(window_size)\n",
    "\n",
    "    rnn_test_loss, _, _ = run_model(rnn_model, X_train, X_test, y_train, y_test, model_name=\"RNN\")\n",
    "    lstm_test_loss, _, _ = run_model(lstm_model, X_train, X_test, y_train, y_test, model_name=\"LSTM\")\n",
    "    gru_test_loss, _, _ = run_model(gru_model, X_train, X_test, y_train, y_test, model_name=\"GRU\")\n",
    "    \n",
    "    return rnn_test_loss, lstm_test_loss, gru_test_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 10일치 데이터를 보고 다음날의 기온을 예측합니다.\n",
    "    rnn_10_test_loss, lstm_10_test_loss, gru_10_test_loss = main(10)\n",
    "    \n",
    "    # 300일치 데이터를 보고 다음날의 기온을 예측합니다.\n",
    "    rnn_300_test_loss, lstm_300_test_loss, gru_300_test_loss = main(300)\n",
    "    \n",
    "    print(\"=\" * 20, \"시계열 길이가 10 인 경우\", \"=\" * 20)\n",
    "    print(\"[RNN ] 테스트 MSE = {:.5f}\".format(rnn_10_test_loss))\n",
    "    print(\"[LSTM] 테스트 MSE = {:.5f}\".format(lstm_10_test_loss))\n",
    "    print(\"[GRU ] 테스트 MSE = {:.5f}\".format(gru_10_test_loss))\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 20, \"시계열 길이가 300 인 경우\", \"=\" * 20)\n",
    "    print(\"[RNN ] 테스트 MSE = {:.5f}\".format(rnn_300_test_loss))\n",
    "    print(\"[LSTM] 테스트 MSE = {:.5f}\".format(lstm_300_test_loss))\n",
    "    print(\"[GRU ] 테스트 MSE = {:.5f}\".format(gru_300_test_loss))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
