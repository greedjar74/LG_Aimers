{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9dd27d7",
   "metadata": {},
   "source": [
    "# Vanilla RNN을 통한 항공 승객 수 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f783e",
   "metadata": {},
   "source": [
    "지시사항\n",
    "데이터셋을 불러와 학습 데이터와 테스트 데이터로 나누는 부분은 load_data 함수에 구현되어 있습니다.\n",
    "\n",
    "시계열 데이터를 사용하여 RNN 기반 모델을 학습할 때는 window size라는 개념을 사용합니다.\n",
    "\n",
    "이는 모델을 한번 학습할 때 사용할 데이터의 개수를 의미하는 것으로, 아래 그림처럼 총 10개의 데이터에서 4개의 데이터를 한번 학습에 사용한다면 window size는 4가 됩니다.\n",
    "\n",
    "\n",
    "\n",
    "이 실습에서는 데이터셋을 구성할 때 각 입력 데이터의 window size가 4가 되도록 설정하였습니다.\n",
    "\n",
    "지시사항에 따라 코드를 완성하세요.\n",
    "\n",
    "SimpleRNN 기반 모델을 만드는 함수 build_rnn_model을 완성하세요. Layer 구성은 아래와 같습니다.\n",
    "layers.SimpleRNN\n",
    "hidden state의 크기: 4\n",
    "input_shape=(window_size, 1)\n",
    "layers.Dense\n",
    "노드 개수: 1개\n",
    "\n",
    "main 함수 내에서 모델 학습을 위한 optimizer, loss 함수, 평가 지표(metrics)를 설정하세요.\n",
    "Optimizer: Adam\n",
    "Learning Rate: 0.001\n",
    "Loss 함수: Mean Squared Error(MSE)\n",
    "\n",
    "모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "batch_size=8\n",
    "epochs=epochs\n",
    "shuffle=True\n",
    "verbose=2\n",
    "이번 실습에서는 예측한 값이 실제 값이 어떻게 나타나는지 마지막에 그래프로 그립니다. 그래프를 보고 값이 잘 예측되고 있는지 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(window_size):\n",
    "    raw_data = pd.read_csv(\"./airline-passengers.csv\")\n",
    "    raw_passengers = raw_data[\"Passengers\"].to_numpy()\n",
    "\n",
    "    # 데이터의 평균과 표준편차 값으로 정규화(표준화) 합니다.\n",
    "    mean_passenger = raw_passengers.mean()\n",
    "    stdv_passenger = raw_passengers.std(ddof=0)\n",
    "    raw_passengers = (raw_passengers - mean_passenger) / stdv_passenger\n",
    "    data_stat = {\"month\": raw_data[\"Month\"], \"mean\": mean_passenger, \"stdv\": stdv_passenger}\n",
    "\n",
    "    # window_size 개의 데이터를 불러와 입력 데이터(X)로 설정하고\n",
    "    # window_size보다 한 시점 뒤의 데이터를 예측할 대상(y)으로 설정하여\n",
    "    # 데이터셋을 구성합니다.\n",
    "    X, y = [], []\n",
    "    for i in range(len(raw_passengers) - window_size):\n",
    "        cur_passenger = raw_passengers[i:i + window_size]\n",
    "        target = raw_passengers[i + window_size]\n",
    "\n",
    "        X.append(list(cur_passenger))\n",
    "        y.append(target)\n",
    "\n",
    "    # X와 y를 numpy array로 변환합니다.\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 각 입력 데이터는 sequence 길이가 window_size이고, featuer 개수는 1개가 되도록\n",
    "    # 마지막에 새로운 차원을 추가합니다.\n",
    "    # 즉, (전체 데이터 개수, window_size) -> (전체 데이터 개수, window_size, 1)이 되도록 변환합니다.\n",
    "    X = X[:, :, np.newaxis]\n",
    "\n",
    "    # 학습 데이터는 전체 데이터의 80%, 테스트 데이터는 20%로 설정합니다.\n",
    "    total_len = len(X)\n",
    "    train_len = int(total_len * 0.8)\n",
    "\n",
    "    X_train, y_train = X[:train_len], y[:train_len]\n",
    "    X_test, y_test = X[train_len:], y[train_len:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, data_stat\n",
    "\n",
    "def build_rnn_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 1번] SimpleRNN 기반 모델을 구성하세요.\n",
    "    model.add(None)\n",
    "\n",
    "    return model\n",
    "    \n",
    "def plot_result(X_true, y_true, y_pred, data_stat):\n",
    "    # 표준화된 결과를 다시 원래 값으로 변환합니다.\n",
    "    y_true_orig = (y_true * data_stat[\"stdv\"]) + data_stat[\"mean\"]\n",
    "    y_pred_orig = (y_pred * data_stat[\"stdv\"]) + data_stat[\"mean\"]\n",
    "\n",
    "    # 테스트 데이터에서 사용한 날짜들만 가져옵니다.\n",
    "    test_month = data_stat[\"month\"][-len(y_true):]\n",
    "\n",
    "    # 모델의 예측값을 실제값과 함께 그래프로 그립니다.\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(y_true_orig, color=\"b\", label=\"True\")\n",
    "    ax.plot(y_pred_orig, color=\"r\", label=\"Prediction\")\n",
    "    ax.set_xticks(list(range(len(test_month))))\n",
    "    ax.set_xticklabels(test_month, rotation=45)\n",
    "    ax.set_title(\"RNN Result\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.savefig(\"airline_rnn.png\")\n",
    "    elice_utils.send_image(\"airline_rnn.png\")\n",
    "\n",
    "def main(model=None, epochs=10):\n",
    "    tf.random.set_seed(2022)\n",
    "\n",
    "    window_size = 4\n",
    "    X_train, X_test, y_train, y_test, data_stat = load_data(window_size)\n",
    "\n",
    "    if model is None:\n",
    "        model = build_rnn_model(window_size)\n",
    "\n",
    "    # TODO: [지시사항 2번] 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "    optimizer = None\n",
    "    None\n",
    "\n",
    "    # TODO: [지시사항 3번] 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "    hist = None\n",
    "    \n",
    "    # 테스트 데이터셋으로 모델을 테스트합니다.\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print()\n",
    "    print(\"테스트 MSE: {:.5f}\".format(test_loss))\n",
    "    print()\n",
    "    \n",
    "    # 모델의 예측값과 실제값을 그래프로 그립니다.\n",
    "    y_pred = model.predict(X_test)\n",
    "    plot_result(X_test, y_test, y_pred, data_stat)\n",
    "\n",
    "    return optimizer, hist\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7c6fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 0s - 28ms/step - loss: 1.9623 - mse: 1.9623\n",
      "Epoch 2/10\n",
      "14/14 - 0s - 1ms/step - loss: 1.7142 - mse: 1.7142\n",
      "Epoch 3/10\n",
      "14/14 - 0s - 1ms/step - loss: 1.4913 - mse: 1.4913\n",
      "Epoch 4/10\n",
      "14/14 - 0s - 1ms/step - loss: 1.2932 - mse: 1.2932\n",
      "Epoch 5/10\n",
      "14/14 - 0s - 1ms/step - loss: 1.1179 - mse: 1.1179\n",
      "Epoch 6/10\n",
      "14/14 - 0s - 1ms/step - loss: 0.9633 - mse: 0.9633\n",
      "Epoch 7/10\n",
      "14/14 - 0s - 1ms/step - loss: 0.8273 - mse: 0.8273\n",
      "Epoch 8/10\n",
      "14/14 - 0s - 1ms/step - loss: 0.7080 - mse: 0.7080\n",
      "Epoch 9/10\n",
      "14/14 - 0s - 1ms/step - loss: 0.6037 - mse: 0.6037\n",
      "Epoch 10/10\n",
      "14/14 - 0s - 996us/step - loss: 0.5132 - mse: 0.5132\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to list.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimizer, hist\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 110\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[1], line 100\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m     98\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m테스트 MSE: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(test_loss))\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# 모델의 예측값과 실제값을 그래프로 그립니다.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to list.__format__"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(window_size):\n",
    "    raw_data = pd.read_csv(\"./airline-passengers.csv\")\n",
    "    raw_passengers = raw_data[\"Passengers\"].to_numpy()\n",
    "\n",
    "    # 데이터의 평균과 표준편차 값으로 정규화(표준화) 합니다.\n",
    "    mean_passenger = raw_passengers.mean()\n",
    "    stdv_passenger = raw_passengers.std(ddof=0)\n",
    "    raw_passengers = (raw_passengers - mean_passenger) / stdv_passenger\n",
    "    data_stat = {\"month\": raw_data[\"Month\"], \"mean\": mean_passenger, \"stdv\": stdv_passenger}\n",
    "\n",
    "    # window_size 개의 데이터를 불러와 입력 데이터(X)로 설정하고\n",
    "    # window_size보다 한 시점 뒤의 데이터를 예측할 대상(y)으로 설정하여\n",
    "    # 데이터셋을 구성합니다.\n",
    "    X, y = [], []\n",
    "    for i in range(len(raw_passengers) - window_size):\n",
    "        cur_passenger = raw_passengers[i:i + window_size]\n",
    "        target = raw_passengers[i + window_size]\n",
    "\n",
    "        X.append(list(cur_passenger))\n",
    "        y.append(target)\n",
    "\n",
    "    # X와 y를 numpy array로 변환합니다.\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 각 입력 데이터는 sequence 길이가 window_size이고, featuer 개수는 1개가 되도록\n",
    "    # 마지막에 새로운 차원을 추가합니다.\n",
    "    # 즉, (전체 데이터 개수, window_size) -> (전체 데이터 개수, window_size, 1)이 되도록 변환합니다.\n",
    "    X = X[:, :, np.newaxis]\n",
    "\n",
    "    # 학습 데이터는 전체 데이터의 80%, 테스트 데이터는 20%로 설정합니다.\n",
    "    total_len = len(X)\n",
    "    train_len = int(total_len * 0.8)\n",
    "\n",
    "    X_train, y_train = X[:train_len], y[:train_len]\n",
    "    X_test, y_test = X[train_len:], y[train_len:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, data_stat\n",
    "\n",
    "def build_rnn_model(window_size):\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO: [지시사항 1번] SimpleRNN 기반 모델을 구성하세요.\n",
    "    model.add(tf.keras.layers.SimpleRNN(4, input_shape=(window_size, 1))) # input_shape=(seq의 길이, feature size)\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "    \n",
    "def plot_result(X_true, y_true, y_pred, data_stat):\n",
    "    # 표준화된 결과를 다시 원래 값으로 변환합니다.\n",
    "    y_true_orig = (y_true * data_stat[\"stdv\"]) + data_stat[\"mean\"]\n",
    "    y_pred_orig = (y_pred * data_stat[\"stdv\"]) + data_stat[\"mean\"]\n",
    "\n",
    "    # 테스트 데이터에서 사용한 날짜들만 가져옵니다.\n",
    "    test_month = data_stat[\"month\"][-len(y_true):]\n",
    "\n",
    "    # 모델의 예측값을 실제값과 함께 그래프로 그립니다.\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(y_true_orig, color=\"b\", label=\"True\")\n",
    "    ax.plot(y_pred_orig, color=\"r\", label=\"Prediction\")\n",
    "    ax.set_xticks(list(range(len(test_month))))\n",
    "    ax.set_xticklabels(test_month, rotation=45)\n",
    "    ax.set_title(\"RNN Result\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    # plt.savefig(\"airline_rnn.png\")\n",
    "    # elice_utils.send_image(\"airline_rnn.png\")\n",
    "x\n",
    "def main(model=None, epochs=10):\n",
    "    tf.random.set_seed(2022)\n",
    "\n",
    "    window_size = 4\n",
    "    X_train, X_test, y_train, y_test, data_stat = load_data(window_size)\n",
    "\n",
    "    if model is None:\n",
    "        model = build_rnn_model(window_size)\n",
    "\n",
    "    # TODO: [지시사항 2번] 모델 학습을 위한 optimizer와 loss 함수를 설정하세요.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "\n",
    "    # TODO: [지시사항 3번] 모델 학습을 위한 hyperparameter를 설정하세요.\n",
    "    hist = model.fit(X_train, y_train, batch_size=8, epochs=epochs, shuffle=True, verbose=2)\n",
    "    \n",
    "    # 테스트 데이터셋으로 모델을 테스트합니다.\n",
    "    test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print()\n",
    "    print(\"테스트 MSE: {:.5f}\".format(test_loss))\n",
    "    print()\n",
    "    \n",
    "    # 모델의 예측값과 실제값을 그래프로 그립니다.\n",
    "    y_pred = model.predict(X_test)\n",
    "    plot_result(X_test, y_test, y_pred, data_stat)\n",
    "\n",
    "    return optimizer, hist\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfa42d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
