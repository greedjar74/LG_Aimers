{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63eaa9f8",
   "metadata": {},
   "source": [
    "# Lasso, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e241bae",
   "metadata": {},
   "source": [
    "실습\n",
    "데이터와 변수 이름을 불러오는 load_data() 함수를 구현합니다.\n",
    "릿지 회귀를 구현하고 데이터를 바탕으로 학습시킨 모델을 반환하는 Ridge_regression() 함수를 완성합니다.\n",
    "라쏘 회귀를 구현하고 데이터를 바탕으로 학습시킨 모델을 반환하는 Lasso_regression() 함수를 완성합니다.\n",
    "실행 버튼을 눌러 릿지 회귀와 라쏘 회귀의 각 변수의 \n",
    "𝛽\n",
    "𝑖\n",
    "β \n",
    "i\n",
    "​\n",
    "  값들을 확인하고, 각 회귀의 특징을 이해해봅니다.\n",
    "그래프를 통해 각 변수들의 \n",
    "𝛽\n",
    "𝑖\n",
    "β \n",
    "i\n",
    "​\n",
    " 의 크기를 살펴보고, 라쏘 회귀와 릿지 회귀의 차이점을 생각해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad760be",
   "metadata": {},
   "source": [
    "## boston data\n",
    "- feature 중 흑인 거주 구역과 관련된 내용이 있어 해당 데이터는 삭제되어 더이상 사용이 불가능하다.\n",
    "- 아래 diabetes를 사용하여 실습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf29d4d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elice_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01melice_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EliceUtils\n\u001b[1;32m      6\u001b[0m elice_utils \u001b[38;5;241m=\u001b[39m EliceUtils()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ridge\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elice_utils'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\"\"\"\n",
    "1. 사이킷런에 존재하는 데이터를 불러오고, \n",
    "   불러온 데이터를 학습용 데이터와 테스트용 데이터로 \n",
    "   분리하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 존재하는 boston 데이터를 \n",
    "           (X, y)의 형태로 불러옵니다. \n",
    "   \n",
    "   Step02. 데이터의 변수 이름을 feature_names 에\n",
    "           저장합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    X, y = load_boston(return_X_y = True)\n",
    "    \n",
    "    feature_names = None\n",
    "    \n",
    "    return X,y,feature_names\n",
    "    \n",
    "\"\"\"\n",
    "2. 릿지(Ridge) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           릿지(Ridge) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Ridge_regression(X, y):\n",
    "    \n",
    "    ridge_reg = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    return ridge_reg\n",
    "\n",
    "\"\"\"\n",
    "3. 라쏘(Lasso) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           라쏘(Lasso) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Lasso_regression(X, y):\n",
    "    \n",
    "    lasso_reg = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    return lasso_reg\n",
    "    \n",
    "# 각 변수의 beta_i 크기를 시각화하는 함수입니다.\n",
    "def plot_graph(coef, title):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.ylim(-1,1)\n",
    "    plt.title(title)\n",
    "    coef.plot(kind='bar')\n",
    "\n",
    "    plt.savefig(\"result.png\")\n",
    "    elice_utils.send_image(\"result.png\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    X,y,feature_names = load_data()\n",
    "    \n",
    "    ridge_reg = Ridge_regression(X, y)\n",
    "    lasso_reg = Lasso_regression(X, y)\n",
    "    \n",
    "    ## Ridge 회귀의 beta_i의 크기를 저장합니다.\n",
    "    ridge_coef = pd.Series(ridge_reg.coef_, feature_names).sort_values()\n",
    "    print(\"Ridge 회귀의 beta_i\\n\", ridge_coef)\n",
    "    \n",
    "    ## Lasso 회귀의 beta_i의 크기를 저장합니다.\n",
    "    lasso_coef = pd.Series(lasso_reg.coef_, feature_names).sort_values()\n",
    "    print(\"Lasso 회귀의 beta_i\\n\", lasso_coef)\n",
    "    \n",
    "    plot_graph(ridge_coef, 'Ridge')\n",
    "    plot_graph(lasso_coef, 'Lasso')\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d13065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "X, y = datasets.fetch_openml('boston', return_X_y=True)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\"\"\"\n",
    "1. 사이킷런에 존재하는 데이터를 불러오고, \n",
    "   불러온 데이터를 학습용 데이터와 테스트용 데이터로 \n",
    "   분리하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 존재하는 boston 데이터를 \n",
    "           (X, y)의 형태로 불러옵니다. \n",
    "   \n",
    "   Step02. 데이터의 변수 이름을 feature_names 에\n",
    "           저장합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    X, y = load_boston(return_X_y = True)\n",
    "    \n",
    "    feature_names = load_boston().feature_names\n",
    "    \n",
    "    return X,y,feature_names\n",
    "    \n",
    "\"\"\"\n",
    "2. 릿지(Ridge) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           릿지(Ridge) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Ridge_regression(X, y):\n",
    "    \n",
    "    ridge_reg = Ridge(alpha=10, )\n",
    "    \n",
    "    ridge_reg.fit(X, y)\n",
    "    \n",
    "    return ridge_reg\n",
    "\n",
    "\"\"\"\n",
    "3. 라쏘(Lasso) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           라쏘(Lasso) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Lasso_regression(X, y):\n",
    "    \n",
    "    lasso_reg = Lasso(alpha=10)\n",
    "    \n",
    "    lasso_reg.fit(X, y)\n",
    "    \n",
    "    return lasso_reg\n",
    "    \n",
    "# 각 변수의 beta_i 크기를 시각화하는 함수입니다.\n",
    "def plot_graph(coef, title):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.ylim(-1,1)\n",
    "    plt.title(title)\n",
    "    coef.plot(kind='bar')\n",
    "\n",
    "    plt.savefig(\"result.png\")\n",
    "\n",
    "\n",
    "X,y,feature_names = load_data()\n",
    "\n",
    "ridge_reg = Ridge_regression(X, y)\n",
    "lasso_reg = Lasso_regression(X, y)\n",
    "\n",
    "## Ridge 회귀의 beta_i의 크기를 저장합니다.\n",
    "ridge_coef = pd.Series(ridge_reg.coef_, feature_names).sort_values()\n",
    "print(\"Ridge 회귀의 beta_i\\n\", ridge_coef)\n",
    "\n",
    "## Lasso 회귀의 beta_i의 크기를 저장합니다.\n",
    "lasso_coef = pd.Series(lasso_reg.coef_, feature_names).sort_values()\n",
    "print(\"Lasso 회귀의 beta_i\\n\", lasso_coef)\n",
    "\n",
    "plot_graph(ridge_coef, 'Ridge')\n",
    "plot_graph(lasso_coef, 'Lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "def sse(clf, X, y):\n",
    "    \"\"\"Calculate the standard squared error of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The standard squared error of the model.\n",
    "    \"\"\"\n",
    "    y_hat = clf.predict(X)\n",
    "    sse = np.sum((y_hat - y) ** 2)\n",
    "    return sse / X.shape[0]\n",
    "\n",
    "\n",
    "def adj_r2_score(clf, X, y):\n",
    "    \"\"\"Calculate the adjusted :math:`R^2` of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The adjusted :math:`R^2` of the model.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    \"\"\"Calculate standard error for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of standard errors for the beta coefficients.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    \"\"\"Calculate t-statistic for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of t-statistic values.\n",
    "    \"\"\"\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "    \"\"\"Calculate p-values for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of p-values.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def summary(clf, X, y, xlabels=None):\n",
    "    \"\"\"\n",
    "    Output summary statistics for a fitted regression model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    xlabels : list, tuple\n",
    "        The labels for the predictors.\n",
    "    \"\"\"\n",
    "    # Check and/or make xlabels\n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "    # Make sure dims of xlabels matches dims of X\n",
    "    if xlabels.shape[0] != ncols:\n",
    "        raise AssertionError(\n",
    "            \"Dimension of xlabels {0} does not match \"\n",
    "            \"X {1}.\".format(xlabels.shape, X.shape))\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate', 'Std. Error', 't value', 'p value']\n",
    "    )\n",
    "    try:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "    except Exception as e:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (\n",
    "                np.round(np.array([clf.intercept_]), 6),\n",
    "                np.round((clf.coef_), 6)\n",
    "            ), axis = 1\n",
    "    )[0,:]\n",
    "    coef_df['Std. Error'] = np.round(coef_se(clf, X, y), 6)\n",
    "    coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "    coef_df['p value'] = np.round(coef_pval(clf, X, y), 6)\n",
    "    # Output results\n",
    "    print('Coefficients:')\n",
    "    print(coef_df.to_string(index=True))\n",
    "    print('---')\n",
    "    print('R-squared:  {0:.6f},    Adjusted R-squared:  {1:.6f},    MSE: {2:.1f}'.format(\n",
    "        metrics.r2_score(y, clf.predict(X)), adj_r2_score(clf, X, y), sse(clf, X, y)))\n",
    "\n",
    "\"\"\"\n",
    "1. 사이킷런에 존재하는 데이터를 불러오고, \n",
    "   불러온 데이터를 학습용 데이터와 테스트용 데이터로 \n",
    "   분리하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 존재하는 boston 데이터를 \n",
    "           (X, y)의 형태로 불러옵니다. \n",
    "   \n",
    "   Step02. 데이터의 변수 이름을 feature_names 에\n",
    "           저장합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(None)\n",
    "    \n",
    "    feature_names = None\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y, feature_names\n",
    "    \n",
    "\"\"\"\n",
    "2. 릿지(Ridge) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           릿지(Ridge) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Ridge_regression(X, y):\n",
    "    \n",
    "    ridge_reg = Ridge(None) # alpha는 penalty term의 크기\n",
    "    \n",
    "    ridge_reg.fit(None)\n",
    "    \n",
    "    return ridge_reg\n",
    "\n",
    "def Ridge_CV_regression(X, y):\n",
    "    penalty = [0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.6, 0.7, 0.9, 1, 10]\n",
    "    rideg_cv_reg = RidgeCV(None)\n",
    "    \n",
    "    rideg_cv_reg.fit(None)\n",
    "    \n",
    "    return rideg_cv_reg\n",
    "\n",
    "\"\"\"\n",
    "3. 라쏘(Lasso) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           라쏘(Lasso) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Lasso_regression(X, y):\n",
    "    lasso_reg = Lasso(None) # alpha는 penalty term의 크기\n",
    "    \n",
    "    lasso_reg.fit(X, y)\n",
    "    \n",
    "    return lasso_reg\n",
    "\n",
    "def Lasso_CV_regression(X, y):\n",
    "    penalty = [0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.6, 0.7, 0.9, 1, 10]\n",
    "    lasso_cv_reg = LassoCV(None)\n",
    "    \n",
    "    lasso_cv_reg.fit(None)\n",
    "    \n",
    "    return lasso_cv_reg\n",
    "    \n",
    "    \n",
    "# 각 변수의 beta_i 크기를 시각화하는 함수입니다.\n",
    "def plot_graph(coef, model_name):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.title(model_name)\n",
    "    coef.plot(kind='bar')\n",
    "    plt.show()\n",
    "    \n",
    "def show_re(model):\n",
    "    score = model.score(test_X, test_y)\n",
    "    pred = model.predict(test_X)\n",
    "    mse = np.sqrt(mean_squared_error(test_y, pred))\n",
    "    print(\"Alpha:{0:.5f}, R2:{1:.7f}, MSE:{2:.7f}, RMSE:{3:.7f}\".format(0.01, score, mse, np.sqrt(mse)))\n",
    "\n",
    "train_X, test_X, train_y, test_y, feature_names = load_data()\n",
    "\n",
    "ridge_reg = Ridge_regression(None)\n",
    "lasso_reg = Lasso_regression(None)\n",
    "rideg_cv_reg = Ridge_CV_regression(None)\n",
    "lasso_cv_reg = Lasso_CV_regression(None)\n",
    "\n",
    "'''\n",
    "## Ridge 회귀의 beta_i의 크기를 저장합니다.\n",
    "ridge_coef = pd.Series(ridge_reg.coef_, feature_names).sort_values()\n",
    "print(\"Ridge 회귀의 beta_i\\n\", ridge_coef)\n",
    "\n",
    "## Lasso 회귀의 beta_i의 크기를 저장합니다.\n",
    "lasso_coef = pd.Series(lasso_reg.coef_, feature_names).sort_values()\n",
    "print(\"Lasso 회귀의 beta_i\\n\", lasso_coef)\n",
    "'''\n",
    "\n",
    "models = [('ridge',ridge_reg), ('rideg_cv_reg',rideg_cv_reg), ('lasso_reg',lasso_reg), ('lasso_cv_reg', lasso_cv_reg)]\n",
    "for model in models:\n",
    "    print(model[0])\n",
    "    model_coef = pd.Series(model[1].coef_, feature_names).sort_values()\n",
    "    print(model_coef)\n",
    "    show_re(model[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5940cee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge\n",
      "s3    -40.407792\n",
      "sex    -1.993635\n",
      "s2     15.560660\n",
      "s1     18.291254\n",
      "age    19.410985\n",
      "s6     39.958266\n",
      "s4     40.832087\n",
      "bp     47.776807\n",
      "s5     56.731697\n",
      "bmi    64.526080\n",
      "dtype: float64\n",
      "Alpha:0.01000, R2:0.1390361, MSE:73.2506242, RMSE:8.5586579\n",
      "\n",
      "rideg_cv_reg\n",
      "s1    -767.212062\n",
      "sex   -274.984633\n",
      "age     38.364165\n",
      "s3      61.199476\n",
      "s4      89.621119\n",
      "s6     123.049114\n",
      "bp     272.049756\n",
      "s2     520.297015\n",
      "bmi    544.858204\n",
      "s5     733.008783\n",
      "dtype: float64\n",
      "Alpha:0.01000, R2:0.4208719, MSE:60.0767157, RMSE:7.7509171\n",
      "\n",
      "lasso_reg\n",
      "age    0.0\n",
      "sex    0.0\n",
      "bmi    0.0\n",
      "bp     0.0\n",
      "s1     0.0\n",
      "s2     0.0\n",
      "s3    -0.0\n",
      "s4     0.0\n",
      "s5     0.0\n",
      "s6     0.0\n",
      "dtype: float64\n",
      "Alpha:0.01000, R2:-0.0039998, MSE:79.1016731, RMSE:8.8939121\n",
      "\n",
      "lasso_cv_reg\n",
      "s1    -886.577226\n",
      "sex   -276.801947\n",
      "age     38.140311\n",
      "s4     103.340835\n",
      "s3     113.071421\n",
      "s6     121.698261\n",
      "bp     272.330273\n",
      "bmi    544.085637\n",
      "s2     616.119231\n",
      "s5     777.322349\n",
      "dtype: float64\n",
      "Alpha:0.01000, R2:0.4200176, MSE:60.1210073, RMSE:7.7537737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "def sse(clf, X, y):\n",
    "    \"\"\"Calculate the standard squared error of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The standard squared error of the model.\n",
    "    \"\"\"\n",
    "    y_hat = clf.predict(X)\n",
    "    sse = np.sum((y_hat - y) ** 2)\n",
    "    return sse / X.shape[0]\n",
    "\n",
    "\n",
    "def adj_r2_score(clf, X, y):\n",
    "    \"\"\"Calculate the adjusted :math:`R^2` of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The adjusted :math:`R^2` of the model.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    \"\"\"Calculate standard error for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of standard errors for the beta coefficients.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    \"\"\"Calculate t-statistic for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of t-statistic values.\n",
    "    \"\"\"\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "    \"\"\"Calculate p-values for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of p-values.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def summary(clf, X, y, xlabels=None):\n",
    "    \"\"\"\n",
    "    Output summary statistics for a fitted regression model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    xlabels : list, tuple\n",
    "        The labels for the predictors.\n",
    "    \"\"\"\n",
    "    # Check and/or make xlabels\n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "    # Make sure dims of xlabels matches dims of X\n",
    "    if xlabels.shape[0] != ncols:\n",
    "        raise AssertionError(\n",
    "            \"Dimension of xlabels {0} does not match \"\n",
    "            \"X {1}.\".format(xlabels.shape, X.shape))\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate', 'Std. Error', 't value', 'p value']\n",
    "    )\n",
    "    try:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "    except Exception as e:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (\n",
    "                np.round(np.array([clf.intercept_]), 6),\n",
    "                np.round((clf.coef_), 6)\n",
    "            ), axis = 1\n",
    "    )[0,:]\n",
    "    coef_df['Std. Error'] = np.round(coef_se(clf, X, y), 6)\n",
    "    coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "    coef_df['p value'] = np.round(coef_pval(clf, X, y), 6)\n",
    "    # Output results\n",
    "    print('Coefficients:')\n",
    "    print(coef_df.to_string(index=True))\n",
    "    print('---')\n",
    "    print('R-squared:  {0:.6f},    Adjusted R-squared:  {1:.6f},    MSE: {2:.1f}'.format(\n",
    "        metrics.r2_score(y, clf.predict(X)), adj_r2_score(clf, X, y), sse(clf, X, y)))\n",
    "\n",
    "\"\"\"\n",
    "1. 사이킷런에 존재하는 데이터를 불러오고, \n",
    "   불러온 데이터를 학습용 데이터와 테스트용 데이터로 \n",
    "   분리하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 존재하는 boston 데이터를 \n",
    "           (X, y)의 형태로 불러옵니다. \n",
    "   \n",
    "   Step02. 데이터의 변수 이름을 feature_names 에\n",
    "           저장합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=98)\n",
    "    \n",
    "    feature_names = load_diabetes().feature_names\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y, feature_names\n",
    "    \n",
    "\"\"\"\n",
    "2. 릿지(Ridge) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           릿지(Ridge) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Ridge_regression(X, y):\n",
    "    \n",
    "    ridge_reg = Ridge(alpha=10) # alpha는 penalty term의 크기\n",
    "    \n",
    "    ridge_reg.fit(X, y)\n",
    "    \n",
    "    return ridge_reg\n",
    "\n",
    "def Ridge_CV_regression(X, y):\n",
    "    penalty = [0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.6, 0.7, 0.9, 1, 10]\n",
    "    rideg_cv_reg = RidgeCV(alphas=penalty, cv=5)\n",
    "    \n",
    "    rideg_cv_reg.fit(X, y)\n",
    "    \n",
    "    return rideg_cv_reg\n",
    "\n",
    "\"\"\"\n",
    "3. 라쏘(Lasso) 회귀를 구현하고, \n",
    "   전체 데이터를 바탕으로 학습시킨 모델을 \n",
    "   반환하는 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 구현되어 있는 \n",
    "           라쏘(Lasso) 회귀 모델을 불러옵니다.\n",
    "           \n",
    "           파라미터 alpha를 10으로 설정합니다.\n",
    "   \n",
    "   Step02. 불러온 모델을 전체 데이터에 맞춰\n",
    "           학습시킵니다.\n",
    "\"\"\"\n",
    "def Lasso_regression(X, y):\n",
    "    lasso_reg = Lasso(alpha=10) # alpha는 penalty term의 크기\n",
    "    \n",
    "    lasso_reg.fit(X, y)\n",
    "    \n",
    "    return lasso_reg\n",
    "\n",
    "def Lasso_CV_regression(X, y):\n",
    "    penalty = [0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.6, 0.7, 0.9, 1, 10]\n",
    "    lasso_cv_reg = LassoCV(alphas=penalty, cv=5)\n",
    "    \n",
    "    lasso_cv_reg.fit(X, y)\n",
    "    \n",
    "    return lasso_cv_reg\n",
    "\n",
    "    \n",
    "def show_re(model):\n",
    "    score = model.score(test_X, test_y)\n",
    "    pred = model.predict(test_X)\n",
    "    mse = np.sqrt(mean_squared_error(test_y, pred))\n",
    "    print(\"Alpha:{0:.5f}, R2:{1:.7f}, MSE:{2:.7f}, RMSE:{3:.7f}\".format(0.01, score, mse, np.sqrt(mse)))\n",
    "\n",
    "train_X, test_X, train_y, test_y, feature_names = load_data()\n",
    "\n",
    "ridge_reg = Ridge_regression(train_X, train_y)\n",
    "lasso_reg = Lasso_regression(train_X, train_y)\n",
    "rideg_cv_reg = Ridge_CV_regression(train_X, train_y)\n",
    "lasso_cv_reg = Lasso_CV_regression(train_X, train_y)\n",
    "\n",
    "'''\n",
    "## Ridge 회귀의 beta_i의 크기를 저장합니다.\n",
    "ridge_coef = pd.Series(ridge_reg.coef_, feature_names).sort_values()\n",
    "print(\"Ridge 회귀의 beta_i\\n\", ridge_coef)\n",
    "\n",
    "## Lasso 회귀의 beta_i의 크기를 저장합니다.\n",
    "lasso_coef = pd.Series(lasso_reg.coef_, feature_names).sort_values()\n",
    "print(\"Lasso 회귀의 beta_i\\n\", lasso_coef)\n",
    "'''\n",
    "\n",
    "models = [('ridge',ridge_reg), ('rideg_cv_reg',rideg_cv_reg), ('lasso_reg',lasso_reg), ('lasso_cv_reg', lasso_cv_reg)]\n",
    "for model in models:\n",
    "    print(model[0])\n",
    "    model_coef = pd.Series(model[1].coef_, feature_names).sort_values()\n",
    "    print(model_coef)\n",
    "    show_re(model[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132142d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23702dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647098ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a68272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05b9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25170cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e90ddc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109252c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744adfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bb9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9b64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5376098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddf5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390213dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03b7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
