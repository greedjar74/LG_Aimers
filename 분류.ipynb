{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ebe4bec",
   "metadata": {},
   "source": [
    "# 실습1\n",
    "- load_data()\n",
    "- LogisticRegression()\n",
    "- logistic_model.fit(train_X, train_y)\n",
    "- logistic_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_plot import *   \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 생성하고 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    X = np.random.normal(size = 100)\n",
    "    y = (X > 0).astype(np.float)\n",
    "    X[X > 0] *= 5\n",
    "    X += .7 * np.random.normal(size = 100)\n",
    "    X = X[:, np.newaxis]\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 100)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y\n",
    "\"\"\"\n",
    "1. 로지스틱 회귀 모델을 구현하고, \n",
    "   학습 결과를 확인할 수 있는 main() 함수를 완성합니다. \n",
    "   \n",
    "   Step01. 데이터를 불러옵니다.\n",
    "   \n",
    "   Step02. 로지스틱 회귀 모델을 정의합니다.\n",
    "   \n",
    "   Step03. 학습용 데이터로 로지스틱 회귀 모델을\n",
    "           학습시킵니다.\n",
    "   \n",
    "   Step04. 테스트용 데이터로 예측한 분류 결과를\n",
    "           확인합니다.\n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = None\n",
    "    \n",
    "    logistic_model = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    predicted = None\n",
    "    \n",
    "    # 예측 결과 확인하기 \n",
    "    print(\"예측 결과 :\", predicted[:10])\n",
    "    \n",
    "    plot_logistic_regression(logistic_model, train_X, train_y)\n",
    "    \n",
    "    return logistic_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c9511",
   "metadata": {},
   "source": [
    "# 실습2\n",
    "- pd.read_csv('dataset.csv')\n",
    "- data.drop('Class', axis=1)\n",
    "- data['Class']\n",
    "- SVC()\n",
    "- svm.fit(train_X, train_y)\n",
    "- svm.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\"\"\"\n",
    "1. data 폴더 내에 있는 dataset.csv파일을 불러오고, \n",
    "   학습용 데이터와 테스트용 데이터를 분리하여 \n",
    "   반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. pandas의 read_csv() 함수를 이용하여 \n",
    "           data 폴더 내에 있는 dataset.csv파일을\n",
    "           불러옵니다. \n",
    "   \n",
    "   Step02. 데이터 X와 y를 분리합니다.\n",
    "           데이터 폴더에 있는 dataset.csv 파일을\n",
    "           확인하고,\n",
    "           \n",
    "           X 데이터에는 'Class' 컬럼을 제외한 나머지 컬럼들을,\n",
    "           y 데이터에는 'Class' 컬럼을 분리하여 저장합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    data = None\n",
    "    \n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    print(X, y)\n",
    "    return train_X, test_X, train_y, test_y\n",
    "    \n",
    "\"\"\"\n",
    "2. SVM 모델을 불러오고,\n",
    "   학습용 데이터에 맞추어 학습시킨 후, \n",
    "   테스트 데이터에 대한 예측 결과를 반환하는 함수를\n",
    "   구현합니다.\n",
    "   \n",
    "   Step01. SVM 모델을 정의합니다.\n",
    "   \n",
    "   Step02. SVM 모델을 학습용 데이터에 맞추어\n",
    "           학습시킵니다.\n",
    "   \n",
    "   Step03. 학습된 모델을 이용하여 \n",
    "           테스트 데이터에 대한 예측을 수행합니다. \n",
    "\"\"\"\n",
    "def SVM(train_X, test_X, train_y, test_y):\n",
    "    \n",
    "    svm = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    pred_y = None\n",
    "    \n",
    "    return pred_y\n",
    "    \n",
    "# 데이터를 불러오고, 모델 예측 결과를 확인하는 main 함수입니다.\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = load_data()\n",
    "    \n",
    "    pred_y = SVM(train_X, test_X, train_y, test_y)\n",
    "    \n",
    "    # SVM 분류 결과값을 출력합니다.\n",
    "    print(\"\\nConfusion matrix : \\n\",confusion_matrix(test_y,pred_y))  \n",
    "    print(\"\\nReport : \\n\",classification_report(test_y,pred_y)) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ecea9",
   "metadata": {},
   "source": [
    "# 실습3 \n",
    "- 8/20\n",
    "- 5/8\n",
    "- 12/20\n",
    "- 2/12\n",
    "- p_confirm_spam * p_spam / (7/20)\n",
    "- p_confirm_ham * p_ham / (7/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f90e6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(spam|confirm) =  0.7142857142857143 \n",
      "P(ham|confirm) =  0.2857142857142857 \n",
      "\n",
      "71.43 % 의 확률로 스팸 메일에 가깝습니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "1. \"확인\" 이라는 키워드가 등장했을 때 \n",
    "    해당 메일이 스팸 메일인지 정상 메일인지\n",
    "    판별하기 위한 함수를 구현합니다.\n",
    "\"\"\"\n",
    "def bayes_theorem():\n",
    "    # 1. P(“스팸 메일”) 의 확률을 구하세요.\n",
    "    p_spam = 8/20\n",
    "    \n",
    "    # 2. P(“확인” | “스팸 메일”) 의 확률을 구하세요.\n",
    "    p_confirm_spam = 5/8\n",
    "    \n",
    "    # 3. P(“정상 메일”) 의 확률을 구하세요.\n",
    "    p_ham = 12/20\n",
    "    \n",
    "    # 4. P(“확인” | \"정상 메일\" ) 의 확률을 구하세요.\n",
    "    p_confirm_ham = 2/12\n",
    "    \n",
    "    # 5. P( \"스팸 메일\" | \"확인\" ) 의 확률을 구하세요.\n",
    "    p_spam_confirm = p_confirm_spam * p_spam / (7/20)\n",
    "    \n",
    "    # 6. P( \"정상 메일\" | \"확인\" ) 의 확률을 구하세요.\n",
    "    p_ham_confirm = p_confirm_ham * p_ham / (7/20)\n",
    "    \n",
    "    return p_spam_confirm, p_ham_confirm\n",
    "\n",
    "def main():\n",
    "    \n",
    "    p_spam_confirm, p_ham_confirm = bayes_theorem()\n",
    "    \n",
    "    print(\"P(spam|confirm) = \",p_spam_confirm, \"\\nP(ham|confirm) = \",p_ham_confirm, \"\\n\")\n",
    "        \n",
    "    # 두 값을 비교하여 확인 키워드가 스팸에 가까운지 정상 메일에 가까운지 확인합니다.\n",
    "    value = [p_spam_confirm, p_ham_confirm]\n",
    "    \n",
    "    if p_spam_confirm > p_ham_confirm:\n",
    "        print( round(value[0] * 100, 2), \"% 의 확률로 스팸 메일에 가깝습니다.\")\n",
    "    else :\n",
    "        print( round(value[1] * 100, 2), \"% 의 확률로 일반 메일에 가깝습니다.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89943e1",
   "metadata": {},
   "source": [
    "# 실습 4\n",
    "- train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "- GaussianNB()\n",
    "- model.fit(train_X, train_y)\n",
    "- model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"\n",
    "1. 데이터를 불러오고, \n",
    "   불러온 데이터를 학습용, 테스트용 데이터로 \n",
    "   분리하여 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 사이킷런에 저장되어 있는 데이터를 \n",
    "           (X, y) 형태로 불러옵니다.\n",
    "   \n",
    "   Step02. 불러온 데이터를 \n",
    "           학습용 데이터와 테스트용 데이터로 분리합니다.\n",
    "           \n",
    "           학습용 데이터 : 80%, 테스트용 데이터 : 20%, \n",
    "           \n",
    "           일관된 결과 확인을 위해 random_state를 \n",
    "           0 으로 설정합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    X, y = load_wine(return_X_y = True)\n",
    "    \n",
    "    print(\"데이터 확인해보기 :\\n\", X[:1])\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = None\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y\n",
    "    \n",
    "\"\"\"\n",
    "2. 가우시안 나이브 베이즈 모델을 불러오고,\n",
    "   학습을 진행한 후 테스트 데이터에 대한 \n",
    "   예측값을 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 가우시안 나이브 베이즈 모델을 정의합니다.\n",
    "   \n",
    "   Step02. 학습용 데이터에 대해 모델을 학습시킵니다.\n",
    "   \n",
    "   Step03. 테스트 데이터에 대한 모델 예측을 수행합니다.\n",
    "\"\"\"\n",
    "def Gaussian_NB(train_X, test_X, train_y, test_y):\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    predicted = None\n",
    "    \n",
    "    return predicted\n",
    "    \n",
    "# 데이터 불러오기, 모델 예측 결과를 확인할 수 있는 함수입니다.\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = load_data()\n",
    "    \n",
    "    predicted = Gaussian_NB(train_X, test_X, train_y, test_y)\n",
    "    \n",
    "    ## 모델 정확도를 통해 분류 성능을 확인해봅니다.\n",
    "    print(\"\\nModel Accuracy : \")\n",
    "    print(accuracy_score(test_y, predicted))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f97c35",
   "metadata": {},
   "source": [
    "# 실습 5\n",
    "- load_data()\n",
    "- confusion_matrix(test_y, y_pred)\n",
    "- cm, test_y, y_pred, classes=class_names\n",
    "- cm, test_y, y_pred, classes=class_names, normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34806e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# 데이터를 불러와 학습용, 테스트용 데이터로 분리하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    X, y = load_wine(return_X_y = True)\n",
    "    class_names = load_wine().target_names\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size =0.3, random_state=0)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y, class_names\n",
    "\n",
    "# Confusion matrix 시각화를 위한 함수입니다.\n",
    "def plot_confusion_matrix(cm, y_true, y_pred, classes, normalize=False, cmap=plt.cm.OrRd):\n",
    "                          \n",
    "    title = \"\"\n",
    "    if normalize:\n",
    "        title = 'Normalized confusion matrix'\n",
    "    else:\n",
    "        title = 'Confusion matrix'\n",
    "    \n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        # 정규화 할 때는 모든 값을 더해서 합이 1이 되도록 각 데이터를 스케일링 합니다.\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(title, \":\\n\", cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # label을 45도 회전해서 보여주도록 변경\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # confusion matrix 실제 값 뿌리기\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.savefig('confusion matrix.png')\n",
    "    elice_utils.send_image('confusion matrix.png')\n",
    "\n",
    "\"\"\"\n",
    "1. 혼동 행렬을 계산하고, \n",
    "   시각화하기 위한 main() 함수를 완성합니다.\n",
    "   \n",
    "   Step01. 데이터를 불러옵니다.\n",
    "   \n",
    "   Step02. 분류 예측 결과를 평가하기 위한 혼동 행렬을 계산합니다.\n",
    "   \n",
    "   Step03. confusion matrix를 시각화하여 출력합니다.\n",
    "           plot_confusion_matrix 함수의 인자를 참고하여 \n",
    "           None을 채워보세요.\n",
    "           \n",
    "           3-1. 혼동 행렬 시각화 결과를 확인합니다. test_y와 y_pred를 비교합니다.\n",
    "           3-2. 함수의 인자 normalize값을 True로 설정하여 \n",
    "                정규화된 혼동 행렬 시각화 결과를 확인합니다.\n",
    "           \n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y, class_names = None\n",
    "    \n",
    "    # SVM 모델로 분류기를 생성하고 학습합니다.\n",
    "    classifier = SVC()\n",
    "    y_pred = classifier.fit(train_X, train_y).predict(test_X)\n",
    "    \n",
    "    cm = None\n",
    "    \n",
    "    plot_confusion_matrix(None, None, None, classes=None)\n",
    "    \n",
    "    # 정규화 된 혼동 행렬을 시각화합니다.\n",
    "    plot_confusion_matrix(None, None, None, classes=None, normalize = None)\n",
    "    \n",
    "    return cm\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a33c2",
   "metadata": {},
   "source": [
    "# 실습6\n",
    "- 아래 코드를 실행하면 표가 나온다. 표를 보고 값을 넣어주면 된다.\n",
    "- 7/10\n",
    "- 2/4\n",
    "- 2/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db87116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def main():\n",
    "    # 실제 값\n",
    "    y_true = pd.Series(\n",
    "        [\"not mafia\", \"not mafia\", \"mafia\", \"not mafia\", \"mafia\", \n",
    "        \"not mafia\", \"not mafia\", \"mafia\", \"not mafia\", \"not mafia\"]\n",
    "        )\n",
    "    # 예측된 값\n",
    "    y_pred = pd.Series(\n",
    "        [\"mafia\", \"mafia\", \"not mafia\", \"not mafia\", \"mafia\", \n",
    "        \"not mafia\", \"not mafia\", \"mafia\", \"not mafia\", \"not mafia\"]\n",
    "        )\n",
    "    \n",
    "    print(\"1. 혼동 행렬 :\\n\",pd.crosstab(y_true, y_pred, rownames=['실제'], colnames=['예측'], margins=True))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    1. 실행 버튼을 클릭하여 \n",
    "       마피아(mafia)와 시민(not mafia)으로 분류된 혼동 행렬을 확인합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    2. 실행 결과값을 토대로 \n",
    "       마피아를 제대로 분석했는 지에 대한 \n",
    "       accuracy, precision, recall을 구합니다.\n",
    "    \"\"\"\n",
    "    accuracy = None\n",
    "    \n",
    "    precision = None\n",
    "    \n",
    "    recall = None\n",
    "    \n",
    "    print(\"\\naccuracy : \", accuracy)\n",
    "    print(\"precision : \", precision)\n",
    "    print(\"recall : \", recall)\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c283fc8",
   "metadata": {},
   "source": [
    "# 실습7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a844edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix results :\n",
      "\t- row : real(test_y) 0 ~ 9 label\n",
      "\t- column : predicted 0 ~ 9 label\n",
      "\n",
      "[[42  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 32  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 41  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 32  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 34  0  0  0  1  1]\n",
      " [ 0  0  0  0  0 35  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 40  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 26  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 36]]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m     draw_digit_images(test_X, test_y, pred)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[3], line 74\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# 학습된 모델로 digit data가 제대로 예측 됐는 지 \u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# 확인하기위한 confusion matrix를 호출합니다.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion matrix results :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m- row : real(test_y) 0 ~ 9 label\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m- column : predicted 0 ~ 9 label\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;241m%\u001b[39m confusion_matrix(test_y, pred))\n\u001b[0;32m---> 74\u001b[0m index_3_precision, index_3_recall, accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex 3의 recall : \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m index_3_recall)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex 3의 precision : \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m index_3_precision)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#from draw_image import draw_digit_images\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "\n",
    "\"\"\"\n",
    "    1. digits 데이터를 불러오고,\n",
    "       학습을 위한 전처리를 진행하는 \n",
    "       load_data() 함수를 구현합니다.\n",
    "       \n",
    "       Step01. digits 데이터를 불러옵니다.\n",
    "       \n",
    "       Step02. 데이터를 학습용 데이터와 \n",
    "               테스트용 데이터로 분리합니다.\n",
    "               (train:80%, test:20%, random_state:100)\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "    2. SVM 분류기를 활용하여 \n",
    "       테스트 데이터에 대한 예측값을 반환하는 \n",
    "       SVM_clf() 함수를 구현합니다.\n",
    "\"\"\"\n",
    "def SVM_clf(train_X, test_X, train_y):\n",
    "    model = SVC()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred = model.predict(test_X)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    3. 출력된 Confusion Matrix 를 통해 \n",
    "       인덱스 3의 precision과 recall, \n",
    "       그리고 전체 데이터에 대한 accuracy를 \n",
    "       계산하여 반환하는 cal_eval() 함수를 구현합니다.\n",
    "\n",
    "\"\"\"\n",
    "def cal_eval(test_y, pred):\n",
    "    \n",
    "    \n",
    "    return index_3_precision, index_3_recall, accuracy\n",
    "\n",
    "\"\"\"\n",
    "    4. 구현한 함수를 활용하여 다중 클래스 분류를 진행하고,\n",
    "       결과를 확인하기 위한 main() 함수를 구현합니다.\n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = load_data()\n",
    "    \n",
    "    pred = SVM_clf(train_X, test_X, train_y)\n",
    "    \n",
    "    \n",
    "    # 학습된 모델로 digit data가 제대로 예측 됐는 지 \n",
    "    # 확인하기위한 confusion matrix를 호출합니다.\n",
    "    print(\"Confusion matrix results :\\n\\t- row : real(test_y) 0 ~ 9 label\\n\\t- column : predicted 0 ~ 9 label\\n\\n%s\\n\"  % confusion_matrix(test_y, pred))\n",
    "    \n",
    "    index_3_precision, index_3_recall, accuracy = None\n",
    "    \n",
    "    print(\"index 3의 recall : %f\" % index_3_recall)\n",
    "    print(\"index 3의 precision : %f\" % index_3_precision)\n",
    "    print(\"전체 accuracy : %f\" % accuracy)\n",
    "    \n",
    "    # 랜덤으로 뽑은 4개의 데이터를 학습된 모델로 \n",
    "    # 제대로 예측 했는 지 시각화 합니다.\n",
    "    draw_digit_images(test_X, test_y, pred)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "## 이미지 출력을 담당하는 부분입니다.\n",
    "def draw_digit_images(test_X, test_y , predicted):\n",
    "    \n",
    "    number = randint(0, len(test_X))\n",
    "    \n",
    "    images_and_labels = list(zip(test_X, test_y))\n",
    "    \n",
    "    for index, (image, label) in enumerate(images_and_labels[number: number + 4]):\n",
    "        plt.subplot(2, 4, index + 1)\n",
    "        plt.axis('off')\n",
    "        image = image.reshape(8,8)\n",
    "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('Training: %i' % label)\n",
    "\n",
    "    images_and_predictions = list(zip(test_X, predicted))\n",
    "    #print(images_and_predictions)\n",
    "    for index, (image, prediction) in enumerate(images_and_predictions[number: number + 4]):\n",
    "        plt.subplot(2, 4, index + 5)\n",
    "        plt.axis('off')\n",
    "        image = image.reshape(8,8)\n",
    "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "    plt.savefig('digit.png')\n",
    "    elice_utils.send_image('digit.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db2e00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c89d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf4775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5165542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad53b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea051d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a43b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7451edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fde33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a4fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b8d021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5de4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0f867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d524a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83551b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294f16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b47a07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8828b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d576cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca88b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c0770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a9a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afa9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3b92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f74c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
