{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e523ab0c",
   "metadata": {},
   "source": [
    "# L1, L2 정규화(Regularization) 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f63dc2",
   "metadata": {},
   "source": [
    "실습\n",
    "L1, L2 정규화를 적용한 모델과 비교하기 위한 하나의 기본 모델을 자유롭게 생성합니다.\n",
    "입력층, 출력층과 관련된 모델 설계 방법은 [실습1]과 동일합니다.\n",
    "\n",
    "위 설명을 참고해서 기본 모델에 L1 정규화를 적용합니다.\n",
    "\n",
    "위 설명을 참고해서 기본 모델에 L2 정규화를 적용합니다.\n",
    "\n",
    "세 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "세 모델에 대해 손실 함수, 최적화(optimize) 알고리즘, 평가 방법(metrics)은 다음과 같이 설정합니다.\n",
    "- 손실 함수(loss) : ‘binary_crossentropy’\n",
    "- 최적화 알고리즘(optimizer) : ‘adam’\n",
    "- 평가 방법(metrics): [‘accuracy’, ‘binary_crossentropy’]\n",
    "\n",
    "실제 모델링 시에는 validation 데이터로 test 데이터를 사용할 시 overfitting의 문제가 발생할 수 있습니다.\n",
    "Tips!\n",
    "L1 정규화 또는 L2 정규화를 적용한 모델의 손실 함수인 binary crossentropy 값, 즉 scores_l1과 scores_l2가 기본 모델의 성능(scores_basic)보다 작은 걸 확인하셨나요? 이로써 L1 정규화 또는 L2 정규화를 적용하면 모델의 성능이 훨씬 좋아진다는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from visual import *\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# 데이터를 전처리하는 함수\n",
    "\n",
    "def sequences_shaping(sequences, dimension):\n",
    "    \n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, word_indices in enumerate(sequences):\n",
    "        results[i, word_indices] = 1.0 \n",
    "    \n",
    "    return results\n",
    "\n",
    "'''\n",
    "1. L1, L2 정규화를 적용한 모델과 비교하기 위한\n",
    "   하나의 기본 모델을 자유롭게 생성합니다.\n",
    "'''\n",
    "\n",
    "def Basic(word_num):\n",
    "    \n",
    "    basic_model = tf.keras.Sequential([None])\n",
    "    \n",
    "    return basic_model\n",
    "\n",
    "'''\n",
    "2. 기본 모델에 L1 정규화를 적용합니다.\n",
    "   입력층과 히든층에만 적용하세요.\n",
    "'''\n",
    "\n",
    "def L1(word_num):\n",
    "    \n",
    "    l1_model = tf.keras.Sequential([None])\n",
    "    \n",
    "    return l1_model\n",
    "\n",
    "'''\n",
    "3. 기본 모델에 L2 정규화를 적용합니다.\n",
    "   입력층과 히든층에만 적용하세요.\n",
    "'''\n",
    "\n",
    "def L2(word_num):\n",
    "    \n",
    "    l2_model = tf.keras.Sequential([None])\n",
    "    \n",
    "    return l2_model\n",
    "\n",
    "\n",
    "'''\n",
    "4. 세 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. Basic, L1, L2 함수를 이용해 세 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 세 모델의 손실 함수, 최적화 알고리즘, \n",
    "           평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 세 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 세 모델을 학습시킵니다. \n",
    "           세 모델 모두 'epochs'는 20,\n",
    "           'batch_size'는 500으로 설정합니다. \n",
    "           검증용 데이터도 설정해주세요.\n",
    "   \n",
    "   Step05. 세 모델을 테스트하고 \n",
    "           binary crossentropy 값을 출력합니다. \n",
    "           셋 중 어느 모델의 성능이 가장 좋은지 확인해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    word_num = 100\n",
    "    data_num = 25000\n",
    "    \n",
    "    # Keras에 내장되어 있는 imdb 데이터 세트를 불러오고 전처리합니다.\n",
    "    \n",
    "    (train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.imdb.load_data(num_words = word_num)\n",
    "    \n",
    "    train_data = sequences_shaping(train_data, dimension = word_num)\n",
    "    test_data = sequences_shaping(test_data, dimension = word_num)\n",
    "    \n",
    "    basic_model = None  # 기본 모델입니다.\n",
    "    l1_model = None     # L1 정규화를 적용할 모델입니다.\n",
    "    l2_model = None     # L2 정규화를 적용할 모델입니다.\n",
    "    \n",
    "    basic_model.compile(None)\n",
    "    l1_model.compile(None)\n",
    "    l2_model.compile(None)\n",
    "    \n",
    "    None\n",
    "    None\n",
    "    None\n",
    "    \n",
    "    basic_history = None\n",
    "    print('\\n')\n",
    "    l1_history = None\n",
    "    print('\\n')\n",
    "    l2_history = None\n",
    "    \n",
    "    scores_basic = None\n",
    "    scores_l1 = None\n",
    "    scores_l2 = None\n",
    "    \n",
    "    print('\\nscores_basic: ', scores_basic[-1])\n",
    "    print('scores_l1: ', scores_l1[-1])\n",
    "    print('scores_l2: ', scores_l2[-1])\n",
    "    \n",
    "    Visulaize([('Basic', basic_history),('L1 Regularization', l1_history), ('L2 Regularization', l2_history)])\n",
    "    \n",
    "    return basic_history, l1_history, l2_history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from visual import *\n",
    "\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# 데이터를 전처리하는 함수\n",
    "\n",
    "def sequences_shaping(sequences, dimension):\n",
    "    \n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, word_indices in enumerate(sequences):\n",
    "        results[i, word_indices] = 1.0 \n",
    "    \n",
    "    return results\n",
    "\n",
    "'''\n",
    "1. L1, L2 정규화를 적용한 모델과 비교하기 위한\n",
    "   하나의 기본 모델을 자유롭게 생성합니다.\n",
    "'''\n",
    "\n",
    "def Basic(word_num):\n",
    "    \n",
    "    basic_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, input_shape=(word_num,), activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "    \n",
    "    return basic_model\n",
    "\n",
    "'''\n",
    "2. 기본 모델에 L1 정규화를 적용합니다.\n",
    "   입력층과 히든층에만 적용하세요.\n",
    "'''\n",
    "\n",
    "def L1(word_num):\n",
    "    \n",
    "    l1_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, input_shape=(word_num,), activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l1(0.001)),\n",
    "        tf.keras.layers.Dense(64, activation='relu',kernel_regularizer = tf.keras.regularizers.l1(0.001)),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return l1_model\n",
    "\n",
    "'''\n",
    "3. 기본 모델에 L2 정규화를 적용합니다.\n",
    "   입력층과 히든층에만 적용하세요.\n",
    "'''\n",
    "\n",
    "def L2(word_num):\n",
    "    \n",
    "    l2_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, input_shape=(word_num,), activation=tf.nn.relu, kernel_regularizer = tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.Dense(64, activation='relu',kernel_regularizer = tf.keras.regularizers.l2(0.001)),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return l2_model\n",
    "\n",
    "\n",
    "'''\n",
    "4. 세 모델을 불러온 후 학습시키고 테스트 데이터에 대해 평가합니다.\n",
    "\n",
    "   Step01. Basic, L1, L2 함수를 이용해 세 모델을 불러옵니다.\n",
    "   \n",
    "   Step02. 세 모델의 손실 함수, 최적화 알고리즘, \n",
    "           평가 방법을 설정합니다.\n",
    "   \n",
    "   Step03. 세 모델의 구조를 확인하는 코드를 작성합니다.\n",
    "   \n",
    "   Step04. 세 모델을 학습시킵니다. \n",
    "           세 모델 모두 'epochs'는 20,\n",
    "           'batch_size'는 500으로 설정합니다. \n",
    "           검증용 데이터도 설정해주세요.\n",
    "   \n",
    "   Step05. 세 모델을 테스트하고 \n",
    "           binary crossentropy 값을 출력합니다. \n",
    "           셋 중 어느 모델의 성능이 가장 좋은지 확인해보세요.\n",
    "'''\n",
    "\n",
    "def main():\n",
    "    \n",
    "    word_num = 100\n",
    "    data_num = 25000\n",
    "    \n",
    "    # Keras에 내장되어 있는 imdb 데이터 세트를 불러오고 전처리합니다.\n",
    "    \n",
    "    (train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.imdb.load_data(num_words = word_num)\n",
    "    \n",
    "    train_data = sequences_shaping(train_data, dimension = word_num)\n",
    "    test_data = sequences_shaping(test_data, dimension = word_num)\n",
    "    \n",
    "    basic_model = Basic(word_num)  # 기본 모델입니다.\n",
    "    l1_model = L1(word_num)     # L1 정규화를 적용할 모델입니다.\n",
    "    l2_model = L2(word_num)     # L2 정규화를 적용할 모델입니다.\n",
    "    \n",
    "    basic_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'binary_crossentropy'])\n",
    "    l1_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'binary_crossentropy'])\n",
    "    l2_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'binary_crossentropy'])\n",
    "    \n",
    "    basic_model.summary()\n",
    "    l1_model.summary()\n",
    "    l2_model.summary()\n",
    "    \n",
    "    basic_history = basic_model.fit(train_data, train_labels, epochs=20, batch_size=500, validation_data = (test_data, test_labels))\n",
    "    print('\\n')\n",
    "    l1_history = l1_model.fit(train_data, train_labels, epochs=20, batch_size=500, validation_data = (test_data, test_labels))\n",
    "    print('\\n')\n",
    "    l2_history = l2_model.fit(train_data, train_labels, epochs=20, batch_size=500, validation_data = (test_data, test_labels))\n",
    "    \n",
    "    scores_basic = basic_model.evaluate(test_data, test_labels)\n",
    "    scores_l1 = l1_model.evaluate(test_data, test_labels)\n",
    "    scores_l2 = l1_model.evaluate(test_data, test_labels)\n",
    "    \n",
    "    print('\\nscores_basic: ', scores_basic[-1])\n",
    "    print('scores_l1: ', scores_l1[-1])\n",
    "    print('scores_l2: ', scores_l2[-1])\n",
    "    \n",
    "    Visulaize([('Basic', basic_history),('L1 Regularization', l1_history), ('L2 Regularization', l2_history)])\n",
    "    \n",
    "    return basic_history, l1_history, l2_history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
