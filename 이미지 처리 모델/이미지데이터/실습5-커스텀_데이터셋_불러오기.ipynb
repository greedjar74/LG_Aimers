{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c6fdb8",
   "metadata": {},
   "source": [
    "# 커스텀 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f4f52",
   "metadata": {},
   "source": [
    "지시사항\n",
    "ImageDataGenerator는 입력 이미지의 픽셀값을 모두 0에서 1사이로 정규화해주는 과정을 추가할 수 있습니다.\n",
    "\n",
    "정규화를 수행하지 않는 것과 수행하는 것을 각각 만들어 먼저 비교해보고, 이후 실제 데이터셋을 불러와 각각 학습용과 검증용 ImageDataGenerator를 생성해보겠습니다.\n",
    "\n",
    "정규화를 수행하지 않는 ImageDataGenerator()를 만드세요.\n",
    "ImageDataGenerator()에 파라미터를 아무것도 전달하지 않으면 됩니다.\n",
    "\n",
    "정규화를 수행하는 ImageDataGenerator()를 만드세요.\n",
    "이미지의 각 픽셀값은 0에서 255 사이의 값을 가지고 있습니다.\n",
    "ImageDataGenerator의 rescale 파라미터에 각 픽셀값을 최대값 255로 나눠주도록 (1/255) 넣어주세요.\n",
    "\n",
    "학습 데이터와 검증 데이터를 위한 ImageDataGenerator를 만드세요.\n",
    "둘 모두 픽셀값을 정규화 하도록 만드세요.\n",
    "train_set의 경로는 dataset/train이 되도록 설정하세요.\n",
    "valid_set의 경로는 dataset/val이 되도록 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a7c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "data_path = \"dataset\"\n",
    "\n",
    "batch_size = 2\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "# path의 데이터를 ImageDataGenerator로 불러와주는 함수\n",
    "def get_dataset(path, datagen):\n",
    "    data_set = datagen.flow_from_directory(path,\n",
    "                                           target_size=(img_width, img_height),\n",
    "                                           batch_size=batch_size,\n",
    "                                           class_mode='categorical')\n",
    "    return data_set\n",
    "\n",
    "def main():\n",
    "    # TODO: [지시사항 1번] 정규화 과정이 없는 ImageDataGenerator를 만드세요.\n",
    "    first_gen = None\n",
    "    first_set = get_dataset(os.path.join(data_path, \"val\"), first_gen)\n",
    "    x, y = first_set.__next__()\n",
    "\n",
    "    print(\"\\n1. 데이터 제너레이터 만들기\")\n",
    "    print(\"first_set\")\n",
    "    print(\"x: {}, y: {}\".format(x.shape, y.shape))\n",
    "    print(x[0][0][0]) # 픽셀이 0~255의 값을 가짐\n",
    "\n",
    "    # TODO: [지시사항 2번] 픽셀값을 0~1의 값으로 정규화 하는 ImageDataGenerator를 만드세요.\n",
    "    second_gen = None\n",
    "    second_set = get_dataset(os.path.join(data_path, \"val\"), second_gen)\n",
    "    x, y = second_set.__next__()    \n",
    "    \n",
    "    print(\"\\n2. 데이터 제너레이터에 정규화 추가하기\")\n",
    "    print(\"second_set\")\n",
    "    print(\"x: {}, y: {}\".format(x.shape, y.shape))\n",
    "    print(x[0][0][0]) # 픽셀이 0~1의 값을 가지는 것을 확인하세요\n",
    "\n",
    "    # TODO: [지시사항 3번] 실제 학습을 위한 ImageDataGenerator를 만드세요.\n",
    "    # 학습 데이터를 위한 ImageDataGenerator를 만드세요.\n",
    "    train_gen = None\n",
    "    \n",
    "    # 학습 데이터셋을 불러오도록 경로명을 설정하세요.\n",
    "    train_set = get_dataset(None, train_gen)\n",
    "\n",
    "    # 검증 데이터를 위한 ImageDataGenerator를 만드세요.\n",
    "    valid_gen = None\n",
    "    \n",
    "    # 검증 데이터셋을 불러오도록 경로명을 설정하세요.\n",
    "    valid_set = get_dataset(None, valid_gen)\n",
    "\n",
    "    print(\"\\n3. 실제 학습을 위한 데이터 제너레이터 작성\")\n",
    "    print(\"학습 데이터의 길이: \", len(train_set))\n",
    "    print(\"검증 데이터의 길이: \", len(valid_set))\n",
    "    \n",
    "    return first_gen, second_gen, train_gen, train_set, valid_gen, valid_set\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ada766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "data_path = \"dataset\"\n",
    "\n",
    "batch_size = 2\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "# path의 데이터를 ImageDataGenerator로 불러와주는 함수\n",
    "def get_dataset(path, datagen):\n",
    "    data_set = datagen.flow_from_directory(path,\n",
    "                                           target_size=(img_width, img_height),\n",
    "                                           batch_size=batch_size,\n",
    "                                           class_mode='categorical')\n",
    "    return data_set\n",
    "\n",
    "def main():\n",
    "    # TODO: [지시사항 1번] 정규화 과정이 없는 ImageDataGenerator를 만드세요.\n",
    "    first_gen = ImageDataGenerator()\n",
    "    first_set = get_dataset(os.path.join(data_path, \"val\"), first_gen)\n",
    "    x, y = first_set.__next__()\n",
    "\n",
    "    print(\"\\n1. 데이터 제너레이터 만들기\")\n",
    "    print(\"first_set\")\n",
    "    print(\"x: {}, y: {}\".format(x.shape, y.shape))\n",
    "    print(x[0][0][0]) # 픽셀이 0~255의 값을 가짐\n",
    "\n",
    "    # TODO: [지시사항 2번] 픽셀값을 0~1의 값으로 정규화 하는 ImageDataGenerator를 만드세요.\n",
    "    second_gen = ImageDataGenerator(rescale=1/255.)\n",
    "    second_set = get_dataset(os.path.join(data_path, \"val\"), second_gen)\n",
    "    x, y = second_set.__next__()    \n",
    "    \n",
    "    print(\"\\n2. 데이터 제너레이터에 정규화 추가하기\")\n",
    "    print(\"second_set\")\n",
    "    print(\"x: {}, y: {}\".format(x.shape, y.shape))\n",
    "    print(x[0][0][0]) # 픽셀이 0~1의 값을 가지는 것을 확인하세요\n",
    "\n",
    "    # TODO: [지시사항 3번] 실제 학습을 위한 ImageDataGenerator를 만드세요.\n",
    "    # 학습 데이터를 위한 ImageDataGenerator를 만드세요.\n",
    "    train_gen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    # 학습 데이터셋을 불러오도록 경로명을 설정하세요.\n",
    "    train_set = get_dataset(os.path.join(data_path, 'train'), train_gen)\n",
    "\n",
    "    # 검증 데이터를 위한 ImageDataGenerator를 만드세요.\n",
    "    valid_gen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    # 검증 데이터셋을 불러오도록 경로명을 설정하세요.\n",
    "    valid_set = get_dataset(os.path.join(data_path, 'val'), valid_gen)\n",
    "\n",
    "    print(\"\\n3. 실제 학습을 위한 데이터 제너레이터 작성\")\n",
    "    print(\"학습 데이터의 길이: \", len(train_set))\n",
    "    print(\"검증 데이터의 길이: \", len(valid_set))\n",
    "    \n",
    "    return first_gen, second_gen, train_gen, train_set, valid_gen, valid_set\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
