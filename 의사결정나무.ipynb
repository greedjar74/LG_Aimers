{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ac0125",
   "metadata": {},
   "source": [
    "# 실습1\n",
    "- male.append(idx)\n",
    "- female.append(idx)\n",
    "- df, female, depth+1\n",
    "- singer.append(i)\n",
    "- df, singer, depth+1\n",
    "- df['성별'][i] == 'M'\n",
    "- df['키'][i] < 180\n",
    "- df['키'][i] < 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0944a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 직업, 키, 성별로 이름을 구분하는 간단한 이진트리 분류기를 만들어보겠습니다.\n",
    "name = ['하하', '김범수', '다현', '아이유', '최민식', '김혜수']\n",
    "job  = ['가수', '가수'  , '가수', '가수'  , '배우'  , '배우']\n",
    "height = [171, 182, 158, 160, 177, 170]\n",
    "sex = ['M', 'M', 'F', 'F', 'M', 'F']\n",
    "\n",
    "# Node 번호를 지정해주기 위한 변수\n",
    "num = 0\n",
    "\n",
    "# Node 정보를 저장하기 위한 딕셔너리 생성\n",
    "node_list = {}\n",
    "\n",
    "# 데이터 프레임 만들기\n",
    "data = pd.DataFrame({'이름': name, '직업': job, '키': height,'성별': sex})\n",
    "print(data,'\\n')\n",
    "\n",
    "\"\"\"\n",
    "1. 성별에 따라 사람을 분류하는 함수를 구현합니다.\n",
    "\"\"\"\n",
    "def Sex_Node(df, depth):\n",
    "    # 전역 변수를 함수 내에서 사용하기 위해 Global 선언\n",
    "    global num\n",
    "    global node_list\n",
    "    # Node num, Depth, Node Name 출력\n",
    "    num +=1\n",
    "    print('Node_num : {} | Node Depth : {} | Sex_Node'.format(num, depth))\n",
    "    node_list[num] = 'Sex_Node'\n",
    "    \n",
    "    male = []\n",
    "    female = []\n",
    "    # 처음 성별 데이터 전체로 분류\n",
    "    for idx, sex in enumerate(df['성별']):\n",
    "        # 성별(sex)이 남자('M')인 경우 male에 Index 저장(append 사용)\n",
    "        if None:\n",
    "            None\n",
    "        # 성별(sex)이 여자('F')인 경우 female에 Index 저장(append 사용)\n",
    "        elif None:\n",
    "            None\n",
    "    \n",
    "    # Index 확인\n",
    "    print('남자 Index : ',male)\n",
    "    print('여자 Index : ',female)\n",
    "    \n",
    "    # 성별 분류 후 직업을 분류하는 Node를 호출합니다.\n",
    "    Job_Node(df, male , depth+1) # male\n",
    "    Job_Node(None, None, None) # female\n",
    "    \n",
    "\"\"\"\n",
    "2. 직업에 따라 사람을 분류하는 함수를 구현합니다.\n",
    "\"\"\"\n",
    "def Job_Node(df,idx, depth):\n",
    "    # 전역 변수를 함수 내에서 사용하기 위해 Global 선언\n",
    "    global num\n",
    "    global node_list\n",
    "    num +=1\n",
    "    \n",
    "    # Node num, Depth, Node Name 출력\n",
    "    print('Node_num : {} | Node Depth : {} | Job_Node'.format(num, depth))\n",
    "    node_list[num] = 'Job_Node'\n",
    "    \n",
    "    # Index 저장을 위한 리스트 \n",
    "    singer = []\n",
    "    \n",
    "    for i in idx:\n",
    "        # 가수인 경우 singer에 Index 저장(append 사용)\n",
    "        if df['직업'][i]=='가수':\n",
    "            None\n",
    "            \n",
    "        # 배우인 경우 Node 번호와 해당 배우의 이름 출력    \n",
    "        else:\n",
    "            num += 1\n",
    "            print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1 ,data['이름'][i]))\n",
    "            node_list[num] = data['이름'][i]\n",
    "    \n",
    "    # 가수인 경우 분류가 끝나지 않았으므로 Index 출력\n",
    "    print('가수 Index : ',singer)\n",
    "    \n",
    "    # 마지막 분류 기준인 키를 통해 가수를 분류\n",
    "    Height_Node(None, None, None)\n",
    "\n",
    "\"\"\"\n",
    "3. 키에 따라 사람을 분류하는 함수를 구현합니다.\n",
    "\"\"\"\n",
    "def Height_Node(df,idx, depth):\n",
    "    # 전역 변수를 함수 내에서 사용하기 위해 Global 선언\n",
    "    global num\n",
    "    global node_list\n",
    "    num +=1\n",
    "    # Node num, Depth, Node Name 출력\n",
    "    print('Node_num : {} | Node Depth : {} | Height_Node'.format(num, depth))\n",
    "    node_list[num] = 'Height_Node'\n",
    "    \n",
    "    for i in idx:\n",
    "        num +=1\n",
    "        # 성별에 따라 키의 기준이 다르기 때문에 성별을 우선 분류\n",
    "        if None:\n",
    "            # 남자의 경우 키에 따라 분류\n",
    "            # 키가 180보다 작은 경우\n",
    "            if None:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1,data['이름'][i]))\n",
    "                node_list[num] = data['이름'][i]\n",
    "            # 키가 180보다 큰 경우\n",
    "            else:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1,data['이름'][i]))\n",
    "                node_list[num] = data['이름'][i]\n",
    "        else:\n",
    "            # 여자의 경우 키에 따라 분류\n",
    "            # 키가 160보다 작은 경우\n",
    "            if None:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1,data['이름'][i]))\n",
    "                node_list[num] = data['이름'][i]\n",
    "            # 키가 160보다 큰 경우\n",
    "            else:\n",
    "                print('Node_num : {} | Node Depth : {} | Name : {}'.format(num, depth+1,data['이름'][i]))\n",
    "                node_list[num] = data['이름'][i]\n",
    "\n",
    "def main():\n",
    "    # 첫 번째 분류 기준으로 성별을 설정합니다.\n",
    "    Sex_Node(data, 1)\n",
    "    print(node_list)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b17e78",
   "metadata": {},
   "source": [
    "# 실습2\n",
    "- DecisionTreeRegressor(max_depth=m_depth)\n",
    "- reg.fit(X, y)\n",
    "- reg.predict(X_test)\n",
    "- DT_Reg(X, y, X_test, 1)\n",
    "- DT_Reg(X, y, X_test, 5)\n",
    "- DT_Reg(X, y, X_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "# 랜덤한 데이터 셋을 생성하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    rng = np.random.RandomState(1)\n",
    "    X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "    y = np.sin(X).ravel()\n",
    "    y[::5] += 3 * (0.5 - rng.rand(16))\n",
    "    \n",
    "    return X, y\n",
    "\"\"\"\n",
    "1. 회귀 의사결정 나무 모델을 이용하여\n",
    "   학습 및 예측을 수행한 결과를 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 회귀를 위한 \n",
    "           의사결정 나무 모델을 정의합니다.\n",
    "   \n",
    "   Step02. 정의한 의사결정 나무 모델을 \n",
    "           데이터에 맞추어 학습시킵니다.\n",
    "           \n",
    "   Step03. 학습된 모델을 이용하여 \n",
    "           테스트 데이터에 대한 예측을 수행합니다.\n",
    "\"\"\"\n",
    "def DT_Reg(X, y, X_test, m_depth):\n",
    "    \n",
    "    reg = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    pred = None\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "# 회귀를 위한 의사결정 나무 결과를 그래프로 시각화합니다.\n",
    "def Visualize(X, y, X_test, y_1, y_5, y_20):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(X, y, s=20, edgecolor=\"black\",\n",
    "                c=\"darkorange\", label=\"data\")\n",
    "    plt.plot(X_test, y_1, color=\"cornflowerblue\",\n",
    "             label=\"max_depth=1\", linewidth=2)\n",
    "    plt.plot(X_test, y_5, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "    plt.plot(X_test, y_20, color=\"red\", label=\"max_depth=20\", linewidth=2)\n",
    "    plt.xlabel(\"data\")\n",
    "    plt.ylabel(\"target\")\n",
    "    plt.title(\"Decision Tree Regression\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig('decision_regressor.png')\n",
    "    elice_utils.send_image('decision_regressor.png')\n",
    "    \n",
    "\"\"\"\n",
    "2. 다양한 max_depth 인자를 설정한\n",
    "   회귀 의사결정 나무 모델로 \n",
    "   학습, 예측을 수행한 후 결과를 확인하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 구현된 DT_Reg 함수를 이용하여 \n",
    "           각각 max_depth가 1,5,20 인 의사결정 나무 모델로 \n",
    "           테스트 데이터에 대한 예측을 하고, 그 값을 저장합니다.\n",
    "\"\"\"\n",
    "def main():\n",
    "    \n",
    "    X, y = load_data()\n",
    "    \n",
    "    X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "    \n",
    "    # max_depth = 1\n",
    "    y_1 = None\n",
    "    \n",
    "    # max_depth = 5\n",
    "    y_5 = None\n",
    "    \n",
    "    # max_depth = 20\n",
    "    y_20 = None\n",
    "    \n",
    "    Visualize(X, y, X_test, y_1, y_5, y_20)\n",
    "    \n",
    "    return y_1, y_5, y_20\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0af763",
   "metadata": {},
   "source": [
    "# 실습3\n",
    "- load_iris(return_X_y=True)\n",
    "- train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)\n",
    "- DecisionTreeClassifier()\n",
    "- clf.fit(train_X, train_y)\n",
    "- clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from elice_utils import EliceUtils\n",
    "elice_utils = EliceUtils()\n",
    "\n",
    "\"\"\"\n",
    "1. 데이터를 불러오고,\n",
    "   학습용 데이터와 테스트용 데이터로 분리하여 \n",
    "   반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. load_iris()를 활용해 사이킷런에 저장된 붓꽃 데이터를 불러옵니다.\n",
    "           (return_X_y를 True로 설정합니다)\n",
    "           \n",
    "   Step02. 불러온 데이터를 train_test_split()을 활용하여\n",
    "           학습용 데이터(80%)와 테스트용 데이터(20%)로\n",
    "           분리합니다.\n",
    "           \n",
    "           일관된 결과 확인을 위해 random_state는 \n",
    "           100으로 설정합니다.\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    \n",
    "    X, y = None\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = None\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y\n",
    "    \n",
    "\"\"\"\n",
    "2. 분류 의사결정 나무 모델로 \n",
    "   학습, 예측을 수행한 후 예측 결과를 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. 분류를 위한 \n",
    "           의사 결정 나무 모델을 정의합니다.\n",
    "           \n",
    "   Step02. 의사 결정 나무를 \n",
    "           학습용 데이터에 대해 학습시킵니다.\n",
    "           \n",
    "   Step03. 테스트 데이터에 대한 \n",
    "           분류 결과를 예측합니다.\n",
    "\"\"\"\n",
    "def DT_Clf(train_X, train_y, test_X):\n",
    "    \n",
    "    clf = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    pred = None\n",
    "    \n",
    "    return pred\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = load_data()\n",
    "    \n",
    "    pred = DT_Clf(train_X, train_y, test_X)\n",
    "    print('테스트 데이터에 대한 예측 정확도 : {0:.4f}'.format(accuracy_score(test_y, pred)))\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f11cab6",
   "metadata": {},
   "source": [
    "# 실습4\n",
    "- LogisticRegression()\n",
    "- KNeighborsClassifier()\n",
    "- VotingClassifier(estimators=[('LR', lr_clf), ('KNN', knn_clf)], voting='soft')\n",
    "- vo_clf.fit(train_X, train_y)\n",
    "- vo_clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb62d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 유방암 데이터를 불러오고,학습용 데이터와 테스트용 데이터로 분리하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    \n",
    "    X, y = load_breast_cancer(return_X_y = True)\n",
    "    \n",
    "    train_X, test_X, train_y ,test_y = train_test_split(X, y, test_size = 0.2, random_state = 156)\n",
    "    \n",
    "    return train_X, test_X, train_y ,test_y\n",
    "\"\"\"\n",
    "1. 다양한 모델을 사용하는 VotingClassifier를 정의하여\n",
    "   학습시키고, 예측을 수행한 결과를 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. Voting과 비교할 각각 다른 분류 모델을 불러옵니다.\n",
    "            \n",
    "           불러올 분류 모델은 \n",
    "           LogisticRegression, \n",
    "           KNeighborsClassifier 입니다.\n",
    "        \n",
    "   Step02. Voting에 사용할 분류 모델을 설정하여 \n",
    "           VotingClassifier를 정의합니다.\n",
    "           \n",
    "           estimators로는 \n",
    "           'lr'이라는 이름으로 LogisticRegressor인 lr_clf, \n",
    "           'knn'이라는 이름으로 KNeighborClassifier인 knn_clf를 사용합니다.\n",
    "           Voting 방식은 'soft'로 지정합니다.\n",
    "   \n",
    "   Step03. Voting Classifier를\n",
    "           학습용 데이터에 맞춰 학습을 시킵니다.\n",
    "   \n",
    "   Step04. 테스트 데이터에 대한 예측을 수행합니다.\n",
    "\"\"\"\n",
    "def Voting_Clf(train_X, test_X, train_y ,test_y):\n",
    "    \n",
    "    lr_clf = None\n",
    "    knn_clf = None\n",
    "    \n",
    "    vo_clf = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    pred = None\n",
    "    \n",
    "    return lr_clf, knn_clf, vo_clf, pred\n",
    "    \n",
    "# 데이터를 불러오고, 모델 학습 및 예측을 진행하기 위한 함수입니다.\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y ,test_y = load_data()\n",
    "    \n",
    "    lr_clf, knn_clf,vo_clf, pred = Voting_Clf(train_X, test_X, train_y ,test_y)\n",
    "    \n",
    "    print('> Voting Classifier 정확도 : {0:.4f}\\n'.format(accuracy_score(test_y, pred)))\n",
    "    \n",
    "    # 다른 분류기를 각각 학습했을 때 결과 예측\n",
    "    classifiers = [lr_clf, knn_clf]\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(train_X, train_y)\n",
    "        pred = classifier.predict(test_X)\n",
    "        class_name = classifier.__class__.__name__\n",
    "        print(\"> {0} 정확도 : {1:.4f}\".format(class_name, accuracy_score(test_y, pred)))\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a858b",
   "metadata": {},
   "source": [
    "# 실습5\n",
    "- BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50)\n",
    "- ba_clf.fit(train_X, train_y)\n",
    "- ba_clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 유방암 데이터를 불러오고,학습용 데이터와 테스트용 데이터로 분리하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    X, y = load_breast_cancer(return_X_y = True)\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 156)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y\n",
    "\n",
    "\"\"\"\n",
    "1. 동일한 모델을 사용하는 BaggingClassifier를 정의하여\n",
    "   학습시키고, 예측을 수행한 결과를 반환하는 함수를 구현합니다.\n",
    "   \n",
    "   Step01. Bagging에 사용할 분류 모델을 설정하여 \n",
    "           BaggingClassifier를 정의합니다.\n",
    "           \n",
    "           모델은 의사결정 나무(DecisionTreeClassifier)를\n",
    "           사용합니다.\n",
    "           \n",
    "           n_estimators는 자유롭게 설정합니다.\n",
    "   \n",
    "   Step02. BaggingClassifier를\n",
    "           학습용 데이터에 맞춰 학습을 시킵니다.\n",
    "   \n",
    "   Step03. 테스트 데이터에 대한 예측을 수행합니다.\n",
    "\"\"\"\n",
    "def Bagging_Clf(train_X, test_X, train_y, test_y):\n",
    "    \n",
    "    ba_clf = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    pred = None\n",
    "    \n",
    "    return ba_clf, pred\n",
    "    \n",
    "# 데이터를 불러오고, 모델 학습 및 예측을 진행하기 위한 함수입니다.\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y, test_y = load_data()\n",
    "    \n",
    "    ba_clf, pred = Bagging_Clf(train_X, test_X, train_y, test_y)\n",
    "    \n",
    "    print('Bagging Classifier 정확도 : {0:.4f}'.format(accuracy_score(test_y, pred)))\n",
    "    \n",
    "    # 단일 의사결정 나무를 학습했을 때 결과 예측하기\n",
    "    single_dt = DecisionTreeClassifier()\n",
    "    single_dt.fit(train_X,train_y)\n",
    "    single_pred = single_dt.predict(test_X)\n",
    "    print('Single Decision Tree Classifier 정확도 : {0:.4f}'.format(accuracy_score(test_y, single_pred)))\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee93e0",
   "metadata": {},
   "source": [
    "# 실습6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# 유방암 데이터를 불러오고,학습용 데이터와 테스트용 데이터로 분리하여 반환하는 함수입니다.\n",
    "def load_data():\n",
    "    X, y = load_breast_cancer(return_X_y = True)\n",
    "    \n",
    "    train_X, test_X, train_y ,test_y = train_test_split(X, y, test_size = 0.2, random_state = 156)\n",
    "    \n",
    "    return train_X, test_X, train_y ,test_y\n",
    "    \n",
    "\"\"\"\n",
    "1. 랜덤포레스트 분류 모델을 불러오고,\n",
    "   학습 및 예측을 수행하여 결과를 반환하는 \n",
    "   함수를 구현합니다.\n",
    "   \n",
    "   Step01. 분류를 위한 \n",
    "           랜덤포레스트 모델을 정의합니다.\n",
    "           \n",
    "           random_state 파라미터를 100으로\n",
    "           설정합니다.\n",
    "           \n",
    "           이 외 모든 파라미터는 \n",
    "           자유롭게 설정해보세요. \n",
    "           \n",
    "   Step02. 랜덤포레스트 모델을 \n",
    "           학습용 데이터에 대해 학습시킵니다.\n",
    "           \n",
    "   Step03. 테스트 데이터에 대한 \n",
    "           분류 결과를 예측합니다.\n",
    "\"\"\"\n",
    "def Random_clf(train_X, train_y, test_X):\n",
    "    \n",
    "    rfc = None\n",
    "    \n",
    "    None\n",
    "    \n",
    "    pred = None\n",
    "    \n",
    "    return rfc, pred\n",
    "    \n",
    "    \n",
    "# 데이터를 불러오고, 모델 학습 및 예측을 진행하기 위한 함수입니다.\n",
    "def main():\n",
    "    \n",
    "    train_X, test_X, train_y ,test_y = load_data()\n",
    "    \n",
    "    rfc, pred = Random_clf(train_X, train_y, test_X)\n",
    "    \n",
    "    print('테스트 데이터 예측 정확도 : {0:.4f}'.format(accuracy_score(test_y, pred)))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150baa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4e95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a8ad70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480f4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a86faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34b9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378194fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0c28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f252e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973aef21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea3f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd371f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c4b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de682726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc9449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e7982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c2176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c1ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac63d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb8045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bda51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02746f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba42fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ff46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169b38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db726acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42b769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1906d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc537c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f3440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b74371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffdf2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8efc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42795813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aafa1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ca867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6316910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166898f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c64d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b739f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bbad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1f269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e90101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe109da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5204f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f11d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac2738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f8e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae545b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f8fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44871931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73745dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03138d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c664f857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f90bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20ea33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eeeb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
